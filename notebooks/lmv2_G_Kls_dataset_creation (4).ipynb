{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQoRYuKtRTnY",
        "outputId": "5837f32a-66c4-47b6-a643-7f82e725d3a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzzNPgdGkH6d"
      },
      "source": [
        "## Installing requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Qu7FnzP_lAQ"
      },
      "outputs": [],
      "source": [
        "# ############ Detectron2 pre-built binaries Pytorch default install ############\n",
        "# ! python3 -m pip install --trusted-host=download.pytorch.org https://download.pytorch.org/whl/cu111/torch-1.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "# ! python3 -m pip install --trusted-host=download.pytorch.org https://download.pytorch.org/whl/cu111/torchvision-0.10.1%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "# ############ Detectron2 section ##############\n",
        "# ! pip install \\\n",
        "#    --no-cache-dir pycocotools~=2.0.0 \\\n",
        "#    --no-cache-dir https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.9/detectron2-0.6%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "# ! pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cuy7A-tfRY14",
        "outputId": "cf91c6fc-b85a-496a-a803-8f5bac95b489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git\n",
        "#!pip install -q datasets seqeval\n",
        "!pip install -q datasets==2.2.2 seqeval\n",
        "!python -m pip install -q 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUQ67QTL8151"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41ukmOKy82hx",
        "outputId": "13164739-431c-408d-c2df-4a5d5e7d717c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'layoutlmV2'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "Receiving objects: 100% (10/10), 160.63 KiB | 918.00 KiB/s, done.\n",
            "remote: Total 10 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ],
      "source": [
        "#! rm -r layoutlmv2_fine_tuning\n",
        "! git clone -b main https://github.com/walidamamou/layoutlmV2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "7X18oK4cPm72",
        "outputId": "df8e7cfc-0477-4330-b192-11f63e28a0ae"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/50/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1767156927.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Delete folder and its contents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, dir_fd)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# lstat()/open()/fstat() trick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0morig_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir_fd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m             \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/50/'"
          ]
        }
      ],
      "source": [
        "# import shutil\n",
        "\n",
        "# # Replace with your folder path\n",
        "# folder_path = \"/content/50/\"\n",
        "\n",
        "# # Delete folder and its contents\n",
        "# shutil.rmtree(folder_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj-te24MkXGd"
      },
      "source": [
        "## Get the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlLQaLhp2BIz"
      },
      "outputs": [],
      "source": [
        "#!/bin/bash\n",
        "IOB_DATA_PATH = \"/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/100/\"\n",
        "! cd /content/\n",
        "! rm -r annotation_lm\n",
        "! mkdir annotation_lm\n",
        "! cp -r \"$IOB_DATA_PATH\" ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOQeM7UL1_se"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKYnon40Bsgo",
        "outputId": "1aa7f408-f561-4306-e55c-76d9e49248a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\t       drive\t   layoutlmv2-finetuned      lmv2-output\n",
            "50\t       g_output    layoutlmv2-finetuned.zip  sample_data\n",
            "annotation_lm  layoutlmV2  lmv2-dataset-output.zip   wandb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCHaZBkBtlE8"
      },
      "outputs": [],
      "source": [
        "!cd /content/100/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DxeXbqjt8Cp",
        "outputId": "89ec1021-40eb-4457-df66-97c0a2f96c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\t       drive\t   layoutlmv2-finetuned      lmv2-output\n",
            "50\t       g_output    layoutlmv2-finetuned.zip  sample_data\n",
            "annotation_lm  layoutlmV2  lmv2-dataset-output.zip   wandb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVsaBbqeto0O",
        "outputId": "80bd04d6-71b3-4486-cea3-02a64e38ffdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP06JRyxBudW",
        "outputId": "7fa46da0-ac85-4889-9c21-bd0f56385913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/100\n",
            "labels.txt\t  w9_forms_075.jpg  w9_forms_158.jpg  w9_forms_242.jpg\n",
            "train_box.txt\t  w9_forms_079.jpg  w9_forms_160.jpg  w9_forms_245.jpg\n",
            "train_image.txt   w9_forms_080.jpg  w9_forms_162.jpg  w9_forms_247.jpg\n",
            "train.txt\t  w9_forms_083.jpg  w9_forms_165.jpg  w9_forms_254.jpg\n",
            "w9_forms_001.jpg  w9_forms_086.jpg  w9_forms_167.jpg  w9_forms_257.jpg\n",
            "w9_forms_003.jpg  w9_forms_088.jpg  w9_forms_172.jpg  w9_forms_260.jpg\n",
            "w9_forms_007.jpg  w9_forms_091.jpg  w9_forms_174.jpg  w9_forms_264.jpg\n",
            "w9_forms_011.jpg  w9_forms_094.jpg  w9_forms_178.jpg  w9_forms_268.jpg\n",
            "w9_forms_015.jpg  w9_forms_098.jpg  w9_forms_181.jpg  w9_forms_276.jpg\n",
            "w9_forms_017.jpg  w9_forms_102.jpg  w9_forms_183.jpg  w9_forms_280.jpg\n",
            "w9_forms_023.jpg  w9_forms_106.jpg  w9_forms_187.jpg  w9_forms_286.jpg\n",
            "w9_forms_026.jpg  w9_forms_108.jpg  w9_forms_189.jpg  w9_forms_288.jpg\n",
            "w9_forms_028.jpg  w9_forms_111.jpg  w9_forms_192.jpg  w9_forms_291.jpg\n",
            "w9_forms_031.jpg  w9_forms_113.jpg  w9_forms_195.jpg  w9_forms_295.jpg\n",
            "w9_forms_034.jpg  w9_forms_116.jpg  w9_forms_197.jpg  w9_forms_298.jpg\n",
            "w9_forms_040.jpg  w9_forms_123.jpg  w9_forms_200.jpg  w9_forms_301.jpg\n",
            "w9_forms_042.jpg  w9_forms_128.jpg  w9_forms_204.jpg  w9_forms_304.jpg\n",
            "w9_forms_044.jpg  w9_forms_132.jpg  w9_forms_209.jpg  w9_forms_307.jpg\n",
            "w9_forms_047.jpg  w9_forms_134.jpg  w9_forms_213.jpg  w9_forms_310.jpg\n",
            "w9_forms_049.jpg  w9_forms_137.jpg  w9_forms_218.jpg  w9_forms_312.jpg\n",
            "w9_forms_054.jpg  w9_forms_140.jpg  w9_forms_222.jpg  w9_forms_320.jpg\n",
            "w9_forms_056.jpg  w9_forms_143.jpg  w9_forms_226.jpg  w9_forms_324.jpg\n",
            "w9_forms_061.jpg  w9_forms_145.jpg  w9_forms_230.jpg  w9_forms_329.jpg\n",
            "w9_forms_065.jpg  w9_forms_147.jpg  w9_forms_233.jpg  w9_forms_333.jpg\n",
            "w9_forms_067.jpg  w9_forms_151.jpg  w9_forms_235.jpg  w9_forms_336.jpg\n",
            "w9_forms_071.jpg  w9_forms_153.jpg  w9_forms_238.jpg  w9_forms_339.jpg\n"
          ]
        }
      ],
      "source": [
        "%cd 100/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT2vv5lwCHKm",
        "outputId": "c364c2e6-7ea2-4654-90e8-447831bd92d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4aMJR9nCMUu",
        "outputId": "13a089a2-aafa-4e00-e0ef-04de13c88b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\t       drive\t   layoutlmv2-finetuned      lmv2-output\n",
            "50\t       g_output    layoutlmv2-finetuned.zip  sample_data\n",
            "annotation_lm  layoutlmV2  lmv2-dataset-output.zip   wandb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIVzzz9Qkbhe"
      },
      "source": [
        "## Training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE3S96xPRi42"
      },
      "outputs": [],
      "source": [
        "#!/bin/bash\n",
        "#preprocessing args\n",
        "TEST_SIZE = 0.2\n",
        "DATA_OUTPUT_PATH = \"/content/lmv2-output/\"\n",
        "\n",
        "#training args\n",
        "PROCESSED_DATA_PATH = DATA_OUTPUT_PATH\n",
        "MODEL_OUTPUT_PATH = \"/content/layoutlmv2-finetuned\"\n",
        "TRAIN_BATCH_SIZE = 1\n",
        "VALID_BATCH_SIZE = 1\n",
        "LEARNING_RATE = 4e-5\n",
        "EPOCHS = 30\n",
        "\n",
        "# other training hyper-parameters for dealing with 0 F1 Score issues\n",
        "LR_SCHEDULER_TYPE = 'constant' #optional constant/linear/cosine/cosine_with_restarts/polynomial/constant_with_warmup defaults to linear\n",
        "WARMUP_RATIO = 0.0 # optional, defaults to 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JjxsocixCqAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8430d05c-66d9-4051-e6c3-295c23b3d738"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘lmv2-output’: File exists\n",
            "mkdir: cannot create directory ‘layoutlmv2-finetuned’: File exists\n",
            "mkdir: cannot create directory ‘g_output’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir lmv2-output\n",
        "!mkdir layoutlmv2-finetuned\n",
        "!mkdir g_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ey81ZyYB-SX",
        "outputId": "04337f59-5a60-4f51-b9df-cc7f3b52985d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\t       drive\t   layoutlmv2-finetuned      lmv2-output\n",
            "50\t       g_output    layoutlmv2-finetuned.zip  sample_data\n",
            "annotation_lm  layoutlmV2  lmv2-dataset-output.zip   wandb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9EYRUZcPHvU",
        "outputId": "910a8b52-96f6-4048-cd00-25c576e2427c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvBoKgqPV2JS"
      },
      "outputs": [],
      "source": [
        "def read_text_file(file_path):\n",
        "  with open(file_path, 'r') as f:\n",
        "    return (f.readlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkAfTCUzTx8j"
      },
      "outputs": [],
      "source": [
        "files = {}\n",
        "files['train_box'] = read_text_file(\"/content/100/train_box.txt\")\n",
        "files['train_image'] = read_text_file(\"/content/100/train_image.txt\")\n",
        "files['train'] = read_text_file(\"/content/100/train.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XiZ1ucRXYLI",
        "outputId": "6067b507-080c-40d6-ef13-281f5c5a48a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114586"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "len(files['train'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNMUcoXuW1YK"
      },
      "outputs": [],
      "source": [
        "assert(len(files['train']) == len(files['train_box']))\n",
        "assert(len(files['train_box']) == len(files['train_image']))\n",
        "assert(len(files['train_image']) == len(files['train']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ0jvv13I_81"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O25l-mj4Tx_h"
      },
      "outputs": [],
      "source": [
        "images = {}\n",
        "for i,row in enumerate(files['train_image']):\n",
        "  if row != '\\n':\n",
        "    image_name = row.split('\\t')[-1]\n",
        "    images.setdefault(image_name.replace('\\n',''),[]).append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v54u-6p5YbJy",
        "outputId": "d504dcbd-4997-476e-b578-6443f982e657"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "len(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF8huj9-Ysq6"
      },
      "outputs": [],
      "source": [
        "words,bboxes,ner_tags,image_path= [],[],[],[]\n",
        "for image,rows in images.items():\n",
        "  #print(image,rows)\n",
        "  #print(image,rows[0],rows[-1])\n",
        "  #print(image,rows[0],rows[-1]+1)\n",
        "  words1=[]\n",
        "  for row in files['train'][rows[0]:rows[-1]+1]:\n",
        "    if row!=\"\\n\":\n",
        "      words1.append(row.split('\\t')[0].replace('\\n',''))\n",
        "  words.append(words1)\n",
        "\n",
        "  ner_tags1=[]\n",
        "  for row in files['train'][rows[0]:rows[-1]+1]:\n",
        "    #print(row)\n",
        "    if row!=\"\\n\":\n",
        "      #c=0\n",
        "      #print(\"hi..\")\n",
        "      ner_tags1.append(row.split('\\t')[1].replace('\\n',''))\n",
        "    #else:\n",
        "      #print(\"..\")\n",
        "  ner_tags.append(ner_tags1)\n",
        "\n",
        "    #ner_tags.append(row.split('\\t')[1].replace('\\n',''))\n",
        "  bboxes1=[]\n",
        "  for box in files['train_box'][rows[0]:rows[-1]+1]:\n",
        "    #print(box)\n",
        "    if box!=\"\\n\":\n",
        "      bboxes1.append(box.split('\\t')[1].replace('\\n',''))\n",
        "      #image_path.append(f\"/content/data/{image}\")\n",
        "    #print(\"---------------------\")\n",
        "  bboxes.append(bboxes1)\n",
        "\n",
        "  #words.append([row.split('\\t')[0].replace('\\n','') for row in files['train'][rows[0]:rows[-1]+1]])\n",
        "  #ner_tags.append([row.split('\\t')[1].replace('\\n','') for row in files['train'][rows[0]:rows[-1]+1]])\n",
        "  #bboxes.append([box.split('\\t')[1].replace('\\n','') for box in files['train_box'][rows[0]:rows[-1]+1]])\n",
        "  image_path.append(f\"/content/100/{image}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRZQOLCruVJQ",
        "outputId": "cf924c6b-84e0-445b-ede8-0a8d774aeeb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 100 100 100\n"
          ]
        }
      ],
      "source": [
        "print(len(words),len(bboxes),len(ner_tags),len(image_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YL0oP7ECCvQd"
      },
      "outputs": [],
      "source": [
        "labels = list(set([tag for doc_tag in ner_tags for tag in doc_tag]))\n",
        "id2label = {v: k for v, k in enumerate(labels)}\n",
        "label2id = {k: v for v, k in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxajDuREy1mI",
        "outputId": "e7afa567-bb6f-4b12-c8d3-7123079699a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'O',\n",
              " 1: 'E-BUSINESS_NAME',\n",
              " 2: 'B-LIST_ACCOUNT_NUMBER',\n",
              " 3: 'S-NAME',\n",
              " 4: 'I-NAME',\n",
              " 5: 'E-CITY_STATE_ZIP_CODE',\n",
              " 6: 'B-SSN',\n",
              " 7: 'S-EIN',\n",
              " 8: 'B-NAME',\n",
              " 9: 'B-EIN',\n",
              " 10: 'S-BUSINESS_NAME',\n",
              " 11: 'E-SSN',\n",
              " 12: 'B-BUSINESS_NAME',\n",
              " 13: 'I-BUSINESS_NAME',\n",
              " 14: 'I-SIGN-DATE',\n",
              " 15: 'E-LIST_ACCOUNT_NUMBER',\n",
              " 16: 'E-NAME',\n",
              " 17: 'S-LIST_ACCOUNT_NUMBER',\n",
              " 18: 'I-SSN',\n",
              " 19: 'E-ADDRESS',\n",
              " 20: 'I-ADDRESS',\n",
              " 21: 'S-SIGN-DATE',\n",
              " 22: 'B-SIGN-DATE',\n",
              " 23: 'I-EIN',\n",
              " 24: 'B-CITY_STATE_ZIP_CODE',\n",
              " 25: 'E-SIGN-DATE',\n",
              " 26: 'I-CITY_STATE_ZIP_CODE',\n",
              " 27: 'B-ADDRESS',\n",
              " 28: 'S-SSN',\n",
              " 29: 'E-EIN',\n",
              " 30: 'I-LIST_ACCOUNT_NUMBER'}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yCY60Xcy3ye",
        "outputId": "5aeb1efd-2c47-474c-fc8a-639308d2abd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'E-BUSINESS_NAME': 1,\n",
              " 'B-LIST_ACCOUNT_NUMBER': 2,\n",
              " 'S-NAME': 3,\n",
              " 'I-NAME': 4,\n",
              " 'E-CITY_STATE_ZIP_CODE': 5,\n",
              " 'B-SSN': 6,\n",
              " 'S-EIN': 7,\n",
              " 'B-NAME': 8,\n",
              " 'B-EIN': 9,\n",
              " 'S-BUSINESS_NAME': 10,\n",
              " 'E-SSN': 11,\n",
              " 'B-BUSINESS_NAME': 12,\n",
              " 'I-BUSINESS_NAME': 13,\n",
              " 'I-SIGN-DATE': 14,\n",
              " 'E-LIST_ACCOUNT_NUMBER': 15,\n",
              " 'E-NAME': 16,\n",
              " 'S-LIST_ACCOUNT_NUMBER': 17,\n",
              " 'I-SSN': 18,\n",
              " 'E-ADDRESS': 19,\n",
              " 'I-ADDRESS': 20,\n",
              " 'S-SIGN-DATE': 21,\n",
              " 'B-SIGN-DATE': 22,\n",
              " 'I-EIN': 23,\n",
              " 'B-CITY_STATE_ZIP_CODE': 24,\n",
              " 'E-SIGN-DATE': 25,\n",
              " 'I-CITY_STATE_ZIP_CODE': 26,\n",
              " 'B-ADDRESS': 27,\n",
              " 'S-SSN': 28,\n",
              " 'E-EIN': 29,\n",
              " 'I-LIST_ACCOUNT_NUMBER': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xltBGcUby1uC"
      },
      "outputs": [],
      "source": [
        "class data_config:\n",
        "  labels = list(set([tag for doc_tag in ner_tags for tag in doc_tag]))\n",
        "  num_labels = len(labels)\n",
        "  id2label = {v: k for v, k in enumerate(labels)}\n",
        "  label2id = {k: v for v, k in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyw69zXd3cy7"
      },
      "outputs": [],
      "source": [
        " dataset_dict = {\n",
        "     'id' : range(len(words)),\n",
        "     'words' : words,\n",
        "     'bboxes' : [[list(map(int,bbox.split())) for bbox in doc]  for doc in bboxes],\n",
        "     'ner_tags' : [[data_config.label2id[tag] for tag in ner_tag] for ner_tag in ner_tags],\n",
        "     'image_path' : image_path\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o63rOIWix_Z0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(dataset_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "S4ulOu-_3jiE",
        "outputId": "bd89f478-ead5-4be3-c8e7-74b59492e1e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                              words  \\\n",
              "0   0  [Form, W, -, 9, Request , for , Taxpayer, Give...   \n",
              "1   1  [11, Form, W, -, 9, Request , for , Taxpayer, ...   \n",
              "2   2  [Form, W, -, 9, (, Rev. , October , 2018, ), R...   \n",
              "3   3  [Form, W, -, 9, Request , for , Taxpayer, Iden...   \n",
              "4   4  [Form, W, -, 9, Request , for , Taxpayer, Iden...   \n",
              "\n",
              "                                              bboxes  \\\n",
              "0  [[75, 73, 104, 79], [111, 59, 151, 80], [143, ...   \n",
              "1  [[22, 2, 36, 5], [80, 80, 107, 86], [115, 65, ...   \n",
              "2  [[76, 73, 105, 79], [111, 59, 151, 80], [143, ...   \n",
              "3  [[71, 82, 99, 87], [107, 67, 148, 87], [139, 6...   \n",
              "4  [[76, 73, 104, 79], [111, 60, 151, 81], [144, ...   \n",
              "\n",
              "                                            ner_tags  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                      image_path  \n",
              "0  /content/100/w9_forms_001.jpg  \n",
              "1  /content/100/w9_forms_003.jpg  \n",
              "2  /content/100/w9_forms_007.jpg  \n",
              "3  /content/100/w9_forms_011.jpg  \n",
              "4  /content/100/w9_forms_015.jpg  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fb2a3d5-c0ad-45d4-82c2-68941f5f89f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>words</th>\n",
              "      <th>bboxes</th>\n",
              "      <th>ner_tags</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[Form, W, -, 9, Request , for , Taxpayer, Give...</td>\n",
              "      <td>[[75, 73, 104, 79], [111, 59, 151, 80], [143, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_001.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[11, Form, W, -, 9, Request , for , Taxpayer, ...</td>\n",
              "      <td>[[22, 2, 36, 5], [80, 80, 107, 86], [115, 65, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_003.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[Form, W, -, 9, (, Rev. , October , 2018, ), R...</td>\n",
              "      <td>[[76, 73, 105, 79], [111, 59, 151, 80], [143, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_007.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[Form, W, -, 9, Request , for , Taxpayer, Iden...</td>\n",
              "      <td>[[71, 82, 99, 87], [107, 67, 148, 87], [139, 6...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_011.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[Form, W, -, 9, Request , for , Taxpayer, Iden...</td>\n",
              "      <td>[[76, 73, 104, 79], [111, 60, 151, 81], [144, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_015.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fb2a3d5-c0ad-45d4-82c2-68941f5f89f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fb2a3d5-c0ad-45d4-82c2-68941f5f89f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fb2a3d5-c0ad-45d4-82c2-68941f5f89f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cd033643-8b4f-43ac-8920-2e6e3a687cfd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cd033643-8b4f-43ac-8920-2e6e3a687cfd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cd033643-8b4f-43ac-8920-2e6e3a687cfd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          83,\n          53,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bboxes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"/content/100/w9_forms_280.jpg\",\n          \"/content/100/w9_forms_172.jpg\",\n          \"/content/100/w9_forms_230.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZwrViLH3_Tt",
        "outputId": "71957953-2811-4c9c-a4a6-da480a42c44e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qb7pa-8R5TF",
        "outputId": "a5685b97-0fe8-4c83-e351-70be039e61b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   id          100 non-null    int64 \n",
            " 1   words       100 non-null    object\n",
            " 2   bboxes      100 non-null    object\n",
            " 3   ner_tags    100 non-null    object\n",
            " 4   image_path  100 non-null    object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 4.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amGzZjS3FLRm"
      },
      "outputs": [],
      "source": [
        "df.id = df.id.apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nB76WYLAFLVQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, valid = train_test_split(df,test_size=TEST_SIZE,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from collections import Counter\n",
        "\n",
        "# def ensure_tag_coverage(df, id2label, test_size=0.2, max_attempts=500):\n",
        "#     target_tags = set(id2label.keys())\n",
        "\n",
        "#     for attempt in range(max_attempts):\n",
        "#         train, valid = train_test_split(df, test_size=test_size, shuffle=True, random_state=attempt)\n",
        "\n",
        "#         # Check validation coverage\n",
        "#         all_valid_tags = []\n",
        "#         for tags in valid['ner_tags'].values:\n",
        "#             all_valid_tags.extend(tags)\n",
        "\n",
        "#         if target_tags.issubset(set(all_valid_tags)):\n",
        "#             print(f\"Found good split on attempt {attempt + 1}\")\n",
        "#             return train, valid\n",
        "\n",
        "#     print(\"Could not find perfect coverage with random splits\")\n",
        "#     return train_test_split(df, test_size=test_size, shuffle=True)\n",
        "\n",
        "# # Use it\n",
        "# train, valid = ensure_tag_coverage(df, id2label, 0.2)"
      ],
      "metadata": {
        "id": "zoYVPpM7wJLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtqIl1EdGf11",
        "outputId": "d4adb3bb-33e8-4d6b-fd12-23b0df554950"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 5)\n",
            "(20, 5)\n"
          ]
        }
      ],
      "source": [
        "print(train.shape)\n",
        "print(valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ruDopP1_9m2t",
        "outputId": "edfcc9ca-fc50-415b-f5ba-59f2e95d3b08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id                                              words  \\\n",
              "7    7  [Form, W, -, 9, Request , for , Taxpayer, Give...   \n",
              "6    6  [Form, W, -, 9, Request , for , Taxpayer, Give...   \n",
              "20  20  [Form, W, -, 9, (, Rev. , October , 2018, ), R...   \n",
              "56  56  [Form, W, -, 9, Request , for , Taxpayer, Give...   \n",
              "30  30  [Form, W, -, 9, Request , for , Taxpayer, Give...   \n",
              "\n",
              "                                               bboxes  \\\n",
              "7   [[76, 82, 104, 87], [111, 67, 152, 88], [143, ...   \n",
              "6   [[73, 75, 101, 81], [108, 61, 149, 82], [140, ...   \n",
              "20  [[76, 72, 105, 77], [111, 57, 150, 79], [146, ...   \n",
              "56  [[80, 80, 107, 86], [116, 66, 155, 87], [147, ...   \n",
              "30  [[76, 75, 105, 81], [112, 60, 153, 81], [144, ...   \n",
              "\n",
              "                                             ner_tags  \\\n",
              "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "20  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "56  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "30  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                       image_path  \n",
              "7   /content/100/w9_forms_026.jpg  \n",
              "6   /content/100/w9_forms_023.jpg  \n",
              "20  /content/100/w9_forms_067.jpg  \n",
              "56  /content/100/w9_forms_181.jpg  \n",
              "30  /content/100/w9_forms_098.jpg  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1397a9cd-5d5e-4b95-bfd4-8d59fd6a0275\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>words</th>\n",
              "      <th>bboxes</th>\n",
              "      <th>ner_tags</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>[Form, W, -, 9, Request , for , Taxpayer, Give...</td>\n",
              "      <td>[[76, 82, 104, 87], [111, 67, 152, 88], [143, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_026.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>[Form, W, -, 9, Request , for , Taxpayer, Give...</td>\n",
              "      <td>[[73, 75, 101, 81], [108, 61, 149, 82], [140, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_023.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>[Form, W, -, 9, (, Rev. , October , 2018, ), R...</td>\n",
              "      <td>[[76, 72, 105, 77], [111, 57, 150, 79], [146, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_067.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>56</td>\n",
              "      <td>[Form, W, -, 9, Request , for , Taxpayer, Give...</td>\n",
              "      <td>[[80, 80, 107, 86], [116, 66, 155, 87], [147, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_181.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>[Form, W, -, 9, Request , for , Taxpayer, Give...</td>\n",
              "      <td>[[76, 75, 105, 81], [112, 60, 153, 81], [144, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>/content/100/w9_forms_098.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1397a9cd-5d5e-4b95-bfd4-8d59fd6a0275')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1397a9cd-5d5e-4b95-bfd4-8d59fd6a0275 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1397a9cd-5d5e-4b95-bfd4-8d59fd6a0275');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8972af96-0429-4f8a-be84-3d3143467728\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8972af96-0429-4f8a-be84-3d3143467728')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8972af96-0429-4f8a-be84-3d3143467728 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 80,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 80,\n        \"samples\": [\n          \"40\",\n          \"7\",\n          \"43\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"words\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bboxes\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_tags\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 80,\n        \"samples\": [\n          \"/content/100/w9_forms_134.jpg\",\n          \"/content/100/w9_forms_026.jpg\",\n          \"/content/100/w9_forms_143.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ApOLNfuGSLx",
        "outputId": "09ed9be4-8265-4734-da70-8a3753acc60a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'O': 112497,\n",
              "         'B-NAME': 95,\n",
              "         'E-NAME': 95,\n",
              "         'B-ADDRESS': 100,\n",
              "         'I-ADDRESS': 249,\n",
              "         'E-ADDRESS': 100,\n",
              "         'B-CITY_STATE_ZIP_CODE': 100,\n",
              "         'I-CITY_STATE_ZIP_CODE': 460,\n",
              "         'E-CITY_STATE_ZIP_CODE': 100,\n",
              "         'S-LIST_ACCOUNT_NUMBER': 79,\n",
              "         'B-SSN': 45,\n",
              "         'I-SSN': 228,\n",
              "         'E-SSN': 45,\n",
              "         'S-SIGN-DATE': 83,\n",
              "         '': 100,\n",
              "         'B-EIN': 29,\n",
              "         'E-EIN': 29,\n",
              "         'S-NAME': 5,\n",
              "         'B-LIST_ACCOUNT_NUMBER': 12,\n",
              "         'I-LIST_ACCOUNT_NUMBER': 12,\n",
              "         'E-LIST_ACCOUNT_NUMBER': 12,\n",
              "         'I-NAME': 34,\n",
              "         'B-BUSINESS_NAME': 17,\n",
              "         'I-BUSINESS_NAME': 12,\n",
              "         'E-BUSINESS_NAME': 17,\n",
              "         'S-EIN': 9,\n",
              "         'B-SIGN-DATE': 2,\n",
              "         'I-SIGN-DATE': 3,\n",
              "         'E-SIGN-DATE': 2,\n",
              "         'S-SSN': 11,\n",
              "         'S-BUSINESS_NAME': 2,\n",
              "         'I-EIN': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "from collections import Counter\n",
        "with open(\"/content/100/train.txt\",encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "a=[]\n",
        "for i in range(len(lines)):\n",
        "    a.append(lines[i].replace(\"\\n\",\"\").split(\"\\t\")[-1])\n",
        "Counter(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awFHFw_O9pac",
        "outputId": "b9239044-4e8e-4ec0-85e0-f876496b5c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]\n"
          ]
        }
      ],
      "source": [
        "total_keys=list(id2label.keys())\n",
        "print(len(total_keys))\n",
        "print(total_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2M4OyeKIOHZ",
        "outputId": "14c44945-509d-4370-faea-cdb1987f8d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}\n",
            "Counter({0: 112497, 26: 460, 20: 249, 18: 228, 27: 100, 19: 100, 24: 100, 5: 100, 8: 95, 16: 95, 21: 83, 17: 79, 6: 45, 11: 45, 4: 34, 9: 29, 29: 29, 12: 17, 1: 17, 2: 12, 30: 12, 15: 12, 13: 12, 28: 11, 7: 9, 3: 5, 14: 3, 22: 2, 25: 2, 10: 2, 23: 2})\n"
          ]
        }
      ],
      "source": [
        "ner_tags_df=df.ner_tags.values\n",
        "all_ner_tags_df=[]\n",
        "for i in range(len(ner_tags_df)):\n",
        "  all_ner_tags_df=all_ner_tags_df+ner_tags_df[i]\n",
        "print(len(set(all_ner_tags_df)))\n",
        "print(set(all_ner_tags_df))\n",
        "print(Counter(all_ner_tags_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jghteoJe900b",
        "outputId": "cbdf7c3b-b248-4162-956b-5627fb8d3317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}\n",
            "Counter({0: 89973, 26: 369, 18: 215, 20: 202, 27: 80, 19: 80, 24: 80, 5: 80, 8: 77, 16: 77, 21: 67, 17: 63, 6: 37, 11: 37, 4: 29, 9: 24, 29: 24, 12: 13, 1: 13, 13: 10, 2: 9, 30: 9, 15: 9, 28: 8, 7: 5, 3: 3, 10: 2, 23: 2, 22: 1, 25: 1})\n",
            "{14}\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "ner_tags_train=train.ner_tags.values\n",
        "all_ner_tags_train=[]\n",
        "for i in range(len(ner_tags_train)):\n",
        "  all_ner_tags_train=all_ner_tags_train+ner_tags_train[i]\n",
        "print(len(set(all_ner_tags_train)))\n",
        "print(set(all_ner_tags_train))\n",
        "print(Counter(all_ner_tags_train))\n",
        "print(set(total_keys) - set(all_ner_tags_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhkGpqI_HCTf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPOlvnpgDP_R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Pbt4UVY9zTj",
        "outputId": "106eb071-d9df-46cb-e112-0e5f45690adb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30}\n",
            "Counter({0: 22524, 26: 91, 20: 47, 27: 20, 19: 20, 24: 20, 5: 20, 8: 18, 16: 18, 17: 16, 21: 16, 18: 13, 6: 8, 11: 8, 4: 5, 9: 5, 29: 5, 12: 4, 1: 4, 7: 4, 2: 3, 30: 3, 15: 3, 28: 3, 14: 3, 13: 2, 3: 2, 22: 1, 25: 1})\n",
            "{10, 23}\n"
          ]
        }
      ],
      "source": [
        "ner_tags_valid=valid.ner_tags.values\n",
        "all_ner_tags_valid=[]\n",
        "for i in range(len(ner_tags_valid)):\n",
        "  all_ner_tags_valid=all_ner_tags_valid+ner_tags_valid[i]\n",
        "print(len(set(all_ner_tags_valid)))\n",
        "print(set(all_ner_tags_valid))\n",
        "print(Counter(all_ner_tags_valid))\n",
        "print(set(total_keys) - set(all_ner_tags_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqlFGMAEC8k8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in6dS0gRB8hS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7OVy_tlhpSa"
      },
      "outputs": [],
      "source": [
        "#train.ner_tags = train.ner_tags.apply(str)\n",
        "#valid.ner_tags = valid.ner_tags.apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2oUdLsXhuaT"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# read dataframe as HuggingFace Datasets object\n",
        "dataset = Dataset.from_pandas(train,preserve_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL8khfeiovR6",
        "outputId": "1c2ffb5f-ab8b-4ccb-c8f2-687eeb4ad738"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'words', 'bboxes', 'ner_tags', 'image_path'],\n",
              "    num_rows: 80\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqn1rWjUxIPs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h7jvIkPp3g8"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from transformers import LayoutLMv2Processor\n",
        "from datasets import Features, Sequence, ClassLabel, Value, Array2D, Array3D\n",
        "processor = LayoutLMv2Processor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\", revision=\"no_ocr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWm30luEqg87"
      },
      "outputs": [],
      "source": [
        "# def preprocess_data(examples):\n",
        "#     images = [Image.open(path).convert(\"RGB\") for path in examples['image_path']]\n",
        "#     words = examples['words']\n",
        "#     boxes = examples['bboxes']\n",
        "#     word_labels = examples['ner_tags']\n",
        "\n",
        "#     encoded_inputs = processor(images, words, boxes=boxes, word_labels=word_labels,\n",
        "#                                padding=\"max_length\", truncation=True)\n",
        "\n",
        "#     return encoded_inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(examples):\n",
        "    images = [Image.open(path).convert(\"RGB\") for path in examples['image_path']]\n",
        "    words = examples['words']\n",
        "    boxes = examples['bboxes']\n",
        "    word_labels = examples['ner_tags']\n",
        "    #encoded_inputs = processor(images, words, boxes=boxes, word_labels=word_labels, padding=\"max_length\", truncation=True)\n",
        "    #encoded_inputs = processor(images, words, boxes=boxes, word_labels=word_labels,max_length=2048, padding=\"max_length\", truncation=True)\n",
        "    encoded_inputs = processor(images, words, boxes=boxes, word_labels=word_labels, padding=\"max_length\", truncation=True,\n",
        "                               max_length=512, return_overflowing_tokens=True, return_offsets_mapping=True,stride=50)\n",
        "    offset_mapping = encoded_inputs.pop('offset_mapping')\n",
        "    overflow_to_sample_mapping = encoded_inputs.pop('overflow_to_sample_mapping')\n",
        "\n",
        "    return encoded_inputs"
      ],
      "metadata": {
        "id": "qhnyigP2zD8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv-WDZQ2iEYi"
      },
      "outputs": [],
      "source": [
        "# we need to define custom features\n",
        "features = Features({\n",
        "        'image': Array3D(dtype=\"int64\", shape=(3, 224, 224)),\n",
        "        'input_ids': Sequence(feature=Value(dtype='int64')),\n",
        "        'attention_mask': Sequence(Value(dtype='int64')),\n",
        "        'token_type_ids': Sequence(Value(dtype='int64')),\n",
        "        'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
        "        'labels': Sequence(ClassLabel(names=data_config.labels)),\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yH2ehE-2zC-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmIKmmsY7S4D"
      },
      "outputs": [],
      "source": [
        "import pyarrow as pa\n",
        "\n",
        "# Enable auto-load for PyExtensionType (trusted data only)\n",
        "pa.PyExtensionType.set_auto_load(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "4937db6fe1b043c887fa86ebb4d0fd70",
            "10ab33cf01b3486197f365cd54fe028b",
            "1d8c54f468d24c3781700b9d04841ca6",
            "9d84e835f7f342189282671bebecbc44",
            "5a630ad62f4d48b3b5f4896d664772d8",
            "cf8e13a3f63140cdad012b2b8ac0592a",
            "75c30bcb71944c5a91dd5a43d8fd55b4",
            "d49fea6bfde54637bd5b11b3544c836e",
            "78a247e69d9247ceaabb7536d7f7262b",
            "07d84ba536f743678d7bbded215e6bc6",
            "61bc57599bb54200aa0bc85c73f772b4"
          ]
        },
        "id": "VdZA_g-OhpVw",
        "outputId": "a30f27c7-a20d-4817-e4b7-2d2640d8da8c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4937db6fe1b043c887fa86ebb4d0fd70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/features/features.py:524: FutureWarning: pyarrow.PyExtensionType is deprecated and will refuse deserialization by default. Instead, please derive from pyarrow.ExtensionType and implement your own serialization mechanism.\n",
            "  pa.PyExtensionType.__init__(self, self.storage_dtype)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset.column_names, features=features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "38e994a246e94330a802662929dd53df",
            "55e15cfe9f734971982667b34ec61fa7",
            "06361584c9284355b6b7f1be7e80f2e6",
            "c8cda3f1020541bb8eef3428808244c9",
            "b71113a1f96f48e39c3bf7ac70f81f2b",
            "8cdf5ff065df4190a0cd4da33ef5081a",
            "8fc1f241043547ef99440b1c26b030d9",
            "16ab2a779e494b3485611c077b83755d",
            "094fdcb2e83744469b685ed4ad32842d",
            "e7cf18cd03cd4ae18bfd3f104862c957",
            "2cef21bf03a84df3ade7ebfd51935e0b"
          ]
        },
        "id": "xaXNgij8DfY-",
        "outputId": "72570c03-1560-4158-e141-7f2e0b9a1204"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38e994a246e94330a802662929dd53df"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# read dataframe as HuggingFace Datasets object\n",
        "dataset1 = Dataset.from_pandas(valid,preserve_index=False)\n",
        "valid_dataset = dataset1.map(preprocess_data, batched=True, remove_columns=dataset1.column_names,features=features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lvsUZutD-2u"
      },
      "outputs": [],
      "source": [
        "train_dataset.set_format(type=\"torch\", device=\"cuda\")\n",
        "valid_dataset.set_format(type=\"torch\", device=\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clgcrJ_-K_Bw",
        "outputId": "bc121ed6-c989-43fe-b3db-37752ffe2473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lmv2-output/\n"
          ]
        }
      ],
      "source": [
        "print(DATA_OUTPUT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a3vcHXjKIlD"
      },
      "outputs": [],
      "source": [
        "if not DATA_OUTPUT_PATH.endswith('/'):\n",
        "  DATA_OUTPUT_PATH+='/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ft728XODK-gp"
      },
      "outputs": [],
      "source": [
        "train_dataset.save_to_disk(f'{DATA_OUTPUT_PATH}train_split')\n",
        "valid_dataset.save_to_disk(f'{DATA_OUTPUT_PATH}eval_split')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vviPRxqCKIoD",
        "outputId": "2b32c4f9-13e8-4fff-9500-ea06bd3efcef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKBtpwTwLSaq",
        "outputId": "e66c3630-c327-4cbc-96af-15349d1751b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lmv2-output\n",
            "eval_split  train_split\n"
          ]
        }
      ],
      "source": [
        "%cd lmv2-output/\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_ZECVQBLmfB",
        "outputId": "8e733c40-d7f7-466c-849f-948907c28955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB4VmciDL_CC",
        "outputId": "6947d7c2-d860-4cb8-f8ae-9158e4f0dea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\t       drive\t   layoutlmv2-finetuned      lmv2-output\n",
            "50\t       g_output    layoutlmv2-finetuned.zip  sample_data\n",
            "annotation_lm  layoutlmV2  lmv2-dataset-output.zip   wandb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB3ARsJmN-pv",
        "outputId": "56894a02-b8ad-4b68-8d38-117fc4b0cd5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/lmv2-output/ (stored 0%)\n",
            "updating: content/lmv2-output/eval_split/ (stored 0%)\n",
            "updating: content/lmv2-output/eval_split/dataset_info.json (deflated 76%)\n",
            "updating: content/lmv2-output/eval_split/dataset.arrow (deflated 91%)\n",
            "updating: content/lmv2-output/eval_split/state.json (deflated 40%)\n",
            "updating: content/lmv2-output/train_split/ (stored 0%)\n",
            "updating: content/lmv2-output/train_split/dataset_info.json (deflated 76%)\n",
            "updating: content/lmv2-output/train_split/dataset.arrow (deflated 91%)\n",
            "updating: content/lmv2-output/train_split/state.json (deflated 40%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/lmv2-dataset-output.zip /content/lmv2-output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UPQ0YKMbeyu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDx6DaNw_HBt",
        "outputId": "f6d66f23-fdd0-4ff8-afd3-7fc16baf18ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.56.0.dev0\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF6z7kumAHyv"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers==4.38.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKE15SK6_HE2",
        "outputId": "87bdae7f-7c68-48ca-8b2a-c6fb7d5287ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.56.0.dev0\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzdtosLdA7z0",
        "outputId": "549e9074-7953-4dbf-dc3c-cab220c705f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.56.0.dev0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnuldj6YLfYE",
        "outputId": "fbcf70f9-7ade-4c29-e5c9-6f053a4a7500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-16 04:02:58.737033: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1755316979.053462   20020 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1755316979.134289   20020 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1755316979.460510   20020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755316979.469254   20020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755316979.469282   20020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1755316979.469295   20020 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "✅ Enabled pyarrow.PyExtensionType auto_load\n",
            "Some weights of LayoutLMv2ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv2-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory. Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/offline-run-20250816_040330-snxzko70\u001b[0m\n",
            "{'loss': 1.7082, 'grad_norm': 2.745678663253784, 'learning_rate': 4e-05, 'epoch': 1.0}\n",
            "  3% 120/3600 [01:06<33:51,  1.71it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:04, 12.89it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:06,  9.31it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:06,  8.92it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:06,  8.50it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:06,  8.28it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  8.26it/s]\u001b[A\n",
            " 15% 9/60 [00:01<00:06,  8.26it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:06,  8.21it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:05,  8.28it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:05,  8.31it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:05,  8.11it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:05,  8.02it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:05,  7.92it/s]\u001b[A\n",
            " 27% 16/60 [00:01<00:05,  8.08it/s]\u001b[A\n",
            " 28% 17/60 [00:02<00:05,  8.13it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:05,  8.12it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:05,  7.94it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:05,  7.95it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:05,  7.67it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  7.61it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:05,  7.34it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:04,  7.43it/s]\u001b[A\n",
            " 43% 26/60 [00:03<00:03,  8.77it/s]\u001b[A\n",
            " 47% 28/60 [00:03<00:03,  9.51it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:02, 10.01it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:02, 10.29it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02, 10.17it/s]\u001b[A\n",
            " 60% 36/60 [00:04<00:02, 10.43it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02, 10.59it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:01, 10.70it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:01, 10.75it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01, 10.65it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01, 10.72it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01, 10.74it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:00, 10.84it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:00, 10.82it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00, 10.78it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00, 10.67it/s]\u001b[A\n",
            " 97% 58/60 [00:06<00:00, 10.76it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 1.2466691732406616, 'eval_ADDRESS_precision': 0.0, 'eval_ADDRESS_recall': 0.0, 'eval_ADDRESS_f1': 0.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.0, 'eval_CITY_STATE_ZIP_CODE_recall': 0.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.0, 'eval_EIN_recall': 0.0, 'eval_EIN_f1': 0.0, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.0, 'eval_NAME_recall': 0.0, 'eval_NAME_f1': 0.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.0, 'eval_SIGN-DATE_recall': 0.0, 'eval_SIGN-DATE_f1': 0.0, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.0, 'eval_SSN_recall': 0.0, 'eval_SSN_f1': 0.0, 'eval_SSN_number': 11, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0.0, 'eval_overall_accuracy': 0.9853652636671505, 'eval_runtime': 7.1894, 'eval_samples_per_second': 8.346, 'eval_steps_per_second': 8.346, 'epoch': 1.0}\n",
            "  3% 120/3600 [01:13<33:51,  1.71it/s]\n",
            "100% 60/60 [00:06<00:00, 11.30it/s]\u001b[A\n",
            "{'loss': 0.9389, 'grad_norm': 1.8430204391479492, 'learning_rate': 4e-05, 'epoch': 2.0}\n",
            "  7% 240/3600 [03:49<29:43,  1.88it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 17.14it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05, 10.36it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:05,  9.10it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:05,  8.68it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:05,  8.52it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:05,  8.47it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:05,  8.49it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:05,  8.45it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:05,  8.39it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:05,  8.16it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:05,  8.17it/s]\u001b[A\n",
            " 27% 16/60 [00:01<00:05,  8.17it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:05,  8.25it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:05,  8.16it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:04,  8.20it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:04,  8.06it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  8.05it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  7.89it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  7.81it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:04,  7.70it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:04,  7.75it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:03,  8.90it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:03,  9.74it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:02, 10.32it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:02, 10.34it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 10.63it/s]\u001b[A\n",
            " 62% 37/60 [00:04<00:02, 10.78it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:01, 10.92it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:01, 10.01it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:01,  9.25it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01,  9.05it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01,  8.95it/s]\u001b[A\n",
            " 77% 46/60 [00:05<00:01,  8.87it/s]\u001b[A\n",
            " 78% 47/60 [00:05<00:01,  8.77it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01,  8.60it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  8.46it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:01,  8.31it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:01,  8.21it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:00,  8.06it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  8.00it/s]\u001b[A\n",
            " 90% 54/60 [00:06<00:00,  8.00it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00,  8.04it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00,  8.11it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00,  8.19it/s]\u001b[A\n",
            " 97% 58/60 [00:06<00:00,  8.27it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.5921889543533325, 'eval_ADDRESS_precision': 0.0, 'eval_ADDRESS_recall': 0.0, 'eval_ADDRESS_f1': 0.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.0, 'eval_CITY_STATE_ZIP_CODE_recall': 0.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.0, 'eval_EIN_recall': 0.0, 'eval_EIN_f1': 0.0, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.0, 'eval_NAME_recall': 0.0, 'eval_NAME_f1': 0.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.0, 'eval_SIGN-DATE_recall': 0.0, 'eval_SIGN-DATE_f1': 0.0, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.0, 'eval_SSN_recall': 0.0, 'eval_SSN_f1': 0.0, 'eval_SSN_number': 11, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0.0, 'eval_overall_accuracy': 0.9853652636671505, 'eval_runtime': 7.7542, 'eval_samples_per_second': 7.738, 'eval_steps_per_second': 7.738, 'epoch': 2.0}\n",
            "  7% 240/3600 [03:56<29:43,  1.88it/s]\n",
            "100% 60/60 [00:07<00:00,  8.07it/s]\u001b[A\n",
            "{'loss': 0.4001, 'grad_norm': 0.591947615146637, 'learning_rate': 4e-05, 'epoch': 3.0}\n",
            " 10% 360/3600 [06:32<27:19,  1.98it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 16.33it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.17it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.26it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.87it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.69it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.56it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:04, 11.11it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 10.95it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 11.02it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 11.13it/s]\u001b[A\n",
            " 38% 23/60 [00:01<00:03, 11.09it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 11.06it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:02, 11.04it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:02, 11.17it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:02, 11.16it/s]\u001b[A\n",
            " 55% 33/60 [00:02<00:02, 11.18it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 11.20it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 11.24it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:01, 10.99it/s]\u001b[A\n",
            " 68% 41/60 [00:03<00:01, 11.09it/s]\u001b[A\n",
            " 72% 43/60 [00:03<00:01, 11.11it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01, 10.21it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01,  9.33it/s]\u001b[A\n",
            " 80% 48/60 [00:04<00:01,  9.01it/s]\u001b[A\n",
            " 82% 49/60 [00:04<00:01,  8.79it/s]\u001b[A\n",
            " 83% 50/60 [00:04<00:01,  8.40it/s]\u001b[A\n",
            " 85% 51/60 [00:04<00:01,  8.39it/s]\u001b[A\n",
            " 87% 52/60 [00:04<00:00,  8.25it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  8.14it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00,  8.13it/s]\u001b[A\n",
            " 92% 55/60 [00:05<00:00,  7.99it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00,  7.81it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00,  7.46it/s]\u001b[A\n",
            " 97% 58/60 [00:05<00:00,  7.49it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.23058052361011505, 'eval_ADDRESS_precision': 0.0, 'eval_ADDRESS_recall': 0.0, 'eval_ADDRESS_f1': 0.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.0, 'eval_CITY_STATE_ZIP_CODE_recall': 0.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.0, 'eval_EIN_recall': 0.0, 'eval_EIN_f1': 0.0, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.0, 'eval_NAME_recall': 0.0, 'eval_NAME_f1': 0.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.0, 'eval_SIGN-DATE_recall': 0.0, 'eval_SIGN-DATE_f1': 0.0, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.0, 'eval_SSN_recall': 0.0, 'eval_SSN_f1': 0.0, 'eval_SSN_number': 11, 'eval_overall_precision': 0.0, 'eval_overall_recall': 0.0, 'eval_overall_f1': 0.0, 'eval_overall_accuracy': 0.9853652636671505, 'eval_runtime': 7.0735, 'eval_samples_per_second': 8.482, 'eval_steps_per_second': 8.482, 'epoch': 3.0}\n",
            " 10% 360/3600 [06:39<27:19,  1.98it/s]\n",
            "100% 60/60 [00:06<00:00,  7.38it/s]\u001b[A\n",
            "{'loss': 0.1784, 'grad_norm': 0.3417532742023468, 'learning_rate': 4e-05, 'epoch': 4.0}\n",
            " 13% 480/3600 [09:23<27:27,  1.89it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 16.07it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05, 10.01it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:06,  8.28it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:06,  7.91it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  7.74it/s]\u001b[A\n",
            " 15% 9/60 [00:01<00:06,  7.50it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:06,  7.38it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:06,  7.23it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:06,  7.26it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:06,  7.44it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:05,  7.69it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:05,  7.83it/s]\u001b[A\n",
            " 27% 16/60 [00:02<00:05,  7.88it/s]\u001b[A\n",
            " 28% 17/60 [00:02<00:05,  7.99it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:05,  8.05it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:05,  8.05it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:05,  7.66it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  7.81it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  7.97it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  7.97it/s]\u001b[A\n",
            " 40% 24/60 [00:03<00:04,  8.04it/s]\u001b[A\n",
            " 42% 25/60 [00:03<00:04,  8.14it/s]\u001b[A\n",
            " 43% 26/60 [00:03<00:04,  8.14it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:04,  7.49it/s]\u001b[A\n",
            " 47% 28/60 [00:03<00:04,  7.73it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:04,  7.53it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  7.67it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:03,  7.77it/s]\u001b[A\n",
            " 53% 32/60 [00:04<00:03,  8.00it/s]\u001b[A\n",
            " 55% 33/60 [00:04<00:03,  8.15it/s]\u001b[A\n",
            " 57% 34/60 [00:04<00:03,  7.98it/s]\u001b[A\n",
            " 58% 35/60 [00:04<00:03,  7.96it/s]\u001b[A\n",
            " 60% 36/60 [00:04<00:03,  7.87it/s]\u001b[A\n",
            " 62% 37/60 [00:04<00:03,  7.34it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:03,  7.28it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:02,  7.53it/s]\u001b[A\n",
            " 67% 40/60 [00:05<00:02,  7.33it/s]\u001b[A\n",
            " 68% 41/60 [00:05<00:02,  7.20it/s]\u001b[A\n",
            " 70% 42/60 [00:05<00:02,  7.21it/s]\u001b[A\n",
            " 72% 43/60 [00:05<00:02,  7.26it/s]\u001b[A\n",
            " 73% 44/60 [00:05<00:02,  7.07it/s]\u001b[A\n",
            " 75% 45/60 [00:05<00:02,  6.93it/s]\u001b[A\n",
            " 78% 47/60 [00:06<00:01,  8.21it/s]\u001b[A\n",
            " 82% 49/60 [00:06<00:01,  9.22it/s]\u001b[A\n",
            " 85% 51/60 [00:06<00:00,  9.94it/s]\u001b[A\n",
            " 88% 53/60 [00:06<00:00, 10.38it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00, 10.55it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00, 10.65it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.11087625473737717, 'eval_ADDRESS_precision': 0.0, 'eval_ADDRESS_recall': 0.0, 'eval_ADDRESS_f1': 0.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.15748031496062992, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.272108843537415, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.0, 'eval_EIN_recall': 0.0, 'eval_EIN_f1': 0.0, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.0, 'eval_NAME_recall': 0.0, 'eval_NAME_f1': 0.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.0, 'eval_SIGN-DATE_recall': 0.0, 'eval_SIGN-DATE_f1': 0.0, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.0, 'eval_SSN_recall': 0.0, 'eval_SSN_f1': 0.0, 'eval_SSN_number': 11, 'eval_overall_precision': 0.15748031496062992, 'eval_overall_recall': 0.16666666666666666, 'eval_overall_f1': 0.16194331983805668, 'eval_overall_accuracy': 0.988953394613772, 'eval_runtime': 7.9363, 'eval_samples_per_second': 7.56, 'eval_steps_per_second': 7.56, 'epoch': 4.0}\n",
            " 13% 480/3600 [09:31<27:27,  1.89it/s]\n",
            "100% 60/60 [00:07<00:00, 10.80it/s]\u001b[A\n",
            "{'loss': 0.1038, 'grad_norm': 0.21296662092208862, 'learning_rate': 4e-05, 'epoch': 5.0}\n",
            " 17% 600/3600 [12:00<28:35,  1.75it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 16.24it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05, 10.54it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:06,  8.99it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:06,  8.70it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  8.23it/s]\u001b[A\n",
            " 15% 9/60 [00:01<00:06,  7.85it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:06,  7.74it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:06,  7.56it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:06,  7.35it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:06,  7.33it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:06,  7.30it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:06,  7.09it/s]\u001b[A\n",
            " 27% 16/60 [00:02<00:06,  7.08it/s]\u001b[A\n",
            " 28% 17/60 [00:02<00:05,  7.38it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:04,  8.83it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  9.73it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:03, 10.25it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 10.63it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:03, 10.46it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:02, 10.57it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:02, 10.54it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:02, 10.76it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 10.91it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 10.65it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:01, 10.85it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:01, 11.07it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:01, 11.12it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01, 11.09it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01, 11.16it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01, 10.98it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:00, 11.05it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00, 11.08it/s]\u001b[A\n",
            " 92% 55/60 [00:05<00:00, 11.08it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00, 11.15it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.07649847120046616, 'eval_ADDRESS_precision': 0.0, 'eval_ADDRESS_recall': 0.0, 'eval_ADDRESS_f1': 0.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.29850746268656714, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.45977011494252873, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.0, 'eval_EIN_recall': 0.0, 'eval_EIN_f1': 0.0, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.64, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.8421052631578947, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.7272727272727272, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.0, 'eval_NAME_recall': 0.0, 'eval_NAME_f1': 0.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.5925925925925926, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.7272727272727272, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.46153846153846156, 'eval_SSN_recall': 0.5454545454545454, 'eval_SSN_f1': 0.4999999999999999, 'eval_SSN_number': 11, 'eval_overall_precision': 0.4393939393939394, 'eval_overall_recall': 0.48333333333333334, 'eval_overall_f1': 0.46031746031746035, 'eval_overall_accuracy': 0.9907676181261087, 'eval_runtime': 6.8358, 'eval_samples_per_second': 8.777, 'eval_steps_per_second': 8.777, 'epoch': 5.0}\n",
            " 17% 600/3600 [12:07<28:35,  1.75it/s]\n",
            "100% 60/60 [00:06<00:00, 11.19it/s]\u001b[A\n",
            "{'loss': 0.078, 'grad_norm': 0.16565236449241638, 'learning_rate': 4e-05, 'epoch': 6.0}\n",
            " 20% 720/3600 [14:55<24:04,  1.99it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 16.77it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05, 10.30it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:05,  9.08it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:06,  8.62it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  8.49it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:06,  8.41it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:05,  8.49it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:05,  8.30it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:05,  8.23it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:05,  8.28it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:05,  8.27it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:05,  7.99it/s]\u001b[A\n",
            " 27% 16/60 [00:01<00:05,  8.12it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:05,  8.25it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:05,  8.33it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:04,  8.32it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:04,  8.21it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  8.29it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  8.36it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  8.28it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:04,  8.18it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:04,  8.15it/s]\u001b[A\n",
            " 43% 26/60 [00:03<00:04,  7.97it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:04,  7.94it/s]\u001b[A\n",
            " 47% 28/60 [00:03<00:04,  7.82it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:04,  7.74it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  8.25it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:02,  9.41it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:02,  9.26it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02,  8.71it/s]\u001b[A\n",
            " 58% 35/60 [00:04<00:02,  8.64it/s]\u001b[A\n",
            " 60% 36/60 [00:04<00:02,  8.55it/s]\u001b[A\n",
            " 62% 37/60 [00:04<00:02,  8.47it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02,  8.47it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:02,  8.52it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:02,  8.47it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:02,  8.49it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:02,  8.30it/s]\u001b[A\n",
            " 72% 43/60 [00:05<00:02,  8.21it/s]\u001b[A\n",
            " 73% 44/60 [00:05<00:01,  8.15it/s]\u001b[A\n",
            " 75% 45/60 [00:05<00:01,  8.22it/s]\u001b[A\n",
            " 77% 46/60 [00:05<00:01,  8.25it/s]\u001b[A\n",
            " 78% 47/60 [00:05<00:01,  8.30it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01,  8.33it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  8.20it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:01,  8.30it/s]\u001b[A\n",
            " 85% 51/60 [00:06<00:01,  8.20it/s]\u001b[A\n",
            " 87% 52/60 [00:06<00:00,  8.28it/s]\u001b[A\n",
            " 88% 53/60 [00:06<00:00,  8.39it/s]\u001b[A\n",
            " 90% 54/60 [00:06<00:00,  8.38it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00,  8.37it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00,  8.51it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00,  8.44it/s]\u001b[A\n",
            " 97% 58/60 [00:06<00:00,  8.43it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.05547808110713959, 'eval_ADDRESS_precision': 0.36363636363636365, 'eval_ADDRESS_recall': 0.8, 'eval_ADDRESS_f1': 0.5000000000000001, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.0, 'eval_CITY_STATE_ZIP_CODE_recall': 0.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.0, 'eval_EIN_recall': 0.0, 'eval_EIN_f1': 0.0, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.5517241379310345, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.8421052631578947, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.6666666666666666, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.42424242424242425, 'eval_NAME_recall': 0.7, 'eval_NAME_f1': 0.5283018867924527, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.7619047619047619, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8421052631578947, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.05263157894736842, 'eval_SSN_recall': 0.09090909090909091, 'eval_SSN_f1': 0.06666666666666667, 'eval_SSN_number': 11, 'eval_overall_precision': 0.36416184971098264, 'eval_overall_recall': 0.525, 'eval_overall_f1': 0.4300341296928328, 'eval_overall_accuracy': 0.995041122399613, 'eval_runtime': 7.9551, 'eval_samples_per_second': 7.542, 'eval_steps_per_second': 7.542, 'epoch': 6.0}\n",
            " 20% 720/3600 [15:03<24:04,  1.99it/s]\n",
            "100% 60/60 [00:07<00:00,  8.28it/s]\u001b[A\n",
            "{'loss': 0.0619, 'grad_norm': 0.10020309686660767, 'learning_rate': 4e-05, 'epoch': 7.0}\n",
            " 23% 840/3600 [17:24<23:39,  1.94it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 17.03it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.58it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.59it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.62it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.49it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.36it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:03, 11.30it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 11.27it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 11.27it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 11.13it/s]\u001b[A\n",
            " 38% 23/60 [00:01<00:03, 11.13it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 11.17it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:02, 11.09it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:02, 11.12it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:02, 11.12it/s]\u001b[A\n",
            " 55% 33/60 [00:02<00:02, 10.68it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 10.58it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 10.66it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:01, 10.79it/s]\u001b[A\n",
            " 68% 41/60 [00:03<00:01, 10.91it/s]\u001b[A\n",
            " 72% 43/60 [00:03<00:01, 10.68it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01, 10.90it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01, 11.02it/s]\u001b[A\n",
            " 82% 49/60 [00:04<00:00, 11.13it/s]\u001b[A\n",
            " 85% 51/60 [00:04<00:00, 11.21it/s]\u001b[A\n",
            " 88% 53/60 [00:04<00:00, 11.24it/s]\u001b[A\n",
            " 92% 55/60 [00:04<00:00, 11.07it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00, 11.14it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.04178829863667488, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.7142857142857143, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.5714285714285714, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.8421052631578947, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.6808510638297872, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.5483870967741935, 'eval_NAME_recall': 0.85, 'eval_NAME_f1': 0.6666666666666665, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.7272727272727273, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8205128205128205, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 1.0, 'eval_SSN_recall': 0.6363636363636364, 'eval_SSN_f1': 0.7777777777777778, 'eval_SSN_number': 11, 'eval_overall_precision': 0.7593984962406015, 'eval_overall_recall': 0.8416666666666667, 'eval_overall_f1': 0.7984189723320158, 'eval_overall_accuracy': 0.9978632478632479, 'eval_runtime': 6.3459, 'eval_samples_per_second': 9.455, 'eval_steps_per_second': 9.455, 'epoch': 7.0}\n",
            " 23% 840/3600 [17:30<23:39,  1.94it/s]\n",
            "100% 60/60 [00:06<00:00, 11.22it/s]\u001b[A\n",
            "{'loss': 0.051, 'grad_norm': 0.09590242803096771, 'learning_rate': 4e-05, 'epoch': 8.0}\n",
            " 27% 960/3600 [20:14<22:03,  1.99it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 17.17it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.47it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.51it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 12.05it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.74it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.60it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:03, 11.46it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 11.16it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 11.27it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 11.26it/s]\u001b[A\n",
            " 38% 23/60 [00:01<00:03, 11.32it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 11.33it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:02, 11.36it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:02, 11.05it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:02, 11.15it/s]\u001b[A\n",
            " 55% 33/60 [00:02<00:02, 11.23it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 11.28it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 11.34it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:01, 11.36it/s]\u001b[A\n",
            " 68% 41/60 [00:03<00:01, 11.19it/s]\u001b[A\n",
            " 72% 43/60 [00:03<00:01, 11.28it/s]\u001b[A\n",
            " 75% 45/60 [00:03<00:01, 11.32it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01, 11.17it/s]\u001b[A\n",
            " 82% 49/60 [00:04<00:01,  9.69it/s]\u001b[A\n",
            " 85% 51/60 [00:04<00:01,  8.89it/s]\u001b[A\n",
            " 87% 52/60 [00:04<00:00,  8.54it/s]\u001b[A\n",
            " 88% 53/60 [00:04<00:00,  8.34it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00,  8.21it/s]\u001b[A\n",
            " 92% 55/60 [00:05<00:00,  8.28it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00,  8.33it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00,  8.33it/s]\u001b[A\n",
            " 97% 58/60 [00:05<00:00,  8.33it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.03513770550489426, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.8181818181818182, 'eval_EIN_recall': 1.0, 'eval_EIN_f1': 0.9, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.64, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.8421052631578947, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.7272727272727272, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.5862068965517241, 'eval_NAME_recall': 0.85, 'eval_NAME_f1': 0.6938775510204082, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.7619047619047619, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8421052631578947, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 1.0, 'eval_SSN_recall': 0.6363636363636364, 'eval_SSN_f1': 0.7777777777777778, 'eval_SSN_number': 11, 'eval_overall_precision': 0.7894736842105263, 'eval_overall_recall': 0.875, 'eval_overall_f1': 0.8300395256916996, 'eval_overall_accuracy': 0.998347040799871, 'eval_runtime': 6.7198, 'eval_samples_per_second': 8.929, 'eval_steps_per_second': 8.929, 'epoch': 8.0}\n",
            " 27% 960/3600 [20:20<22:03,  1.99it/s]\n",
            "100% 60/60 [00:06<00:00,  8.17it/s]\u001b[A\n",
            "{'loss': 0.045, 'grad_norm': 0.06299929320812225, 'learning_rate': 4e-05, 'epoch': 9.0}\n",
            " 30% 1080/3600 [22:31<21:00,  2.00it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 16.72it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.50it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.53it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.92it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.55it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.38it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:04, 11.17it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 11.02it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 11.03it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 10.93it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:03, 10.63it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 10.86it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:03, 10.96it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:02, 11.09it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:02, 11.17it/s]\u001b[A\n",
            " 55% 33/60 [00:02<00:02, 11.00it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 11.09it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 11.08it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:01, 11.16it/s]\u001b[A\n",
            " 68% 41/60 [00:03<00:01, 11.07it/s]\u001b[A\n",
            " 72% 43/60 [00:03<00:01, 10.76it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01,  9.68it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01,  9.22it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01,  9.00it/s]\u001b[A\n",
            " 80% 48/60 [00:04<00:01,  8.55it/s]\u001b[A\n",
            " 82% 49/60 [00:04<00:01,  8.18it/s]\u001b[A\n",
            " 83% 50/60 [00:04<00:01,  7.92it/s]\u001b[A\n",
            " 85% 51/60 [00:04<00:01,  8.02it/s]\u001b[A\n",
            " 87% 52/60 [00:04<00:00,  8.06it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  7.67it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00,  7.87it/s]\u001b[A\n",
            " 92% 55/60 [00:05<00:00,  7.89it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00,  7.77it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00,  7.55it/s]\u001b[A\n",
            " 97% 58/60 [00:05<00:00,  7.55it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.02935287542641163, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.7777777777777778, 'eval_EIN_recall': 0.7777777777777778, 'eval_EIN_f1': 0.7777777777777778, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.5925925925925926, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.8421052631578947, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.6956521739130435, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.8, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 0.888888888888889, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.7619047619047619, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8421052631578947, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 1.0, 'eval_SSN_recall': 0.6363636363636364, 'eval_SSN_f1': 0.7777777777777778, 'eval_SSN_number': 11, 'eval_overall_precision': 0.8217054263565892, 'eval_overall_recall': 0.8833333333333333, 'eval_overall_f1': 0.8514056224899598, 'eval_overall_accuracy': 0.9986292533462344, 'eval_runtime': 7.0928, 'eval_samples_per_second': 8.459, 'eval_steps_per_second': 8.459, 'epoch': 9.0}\n",
            " 30% 1080/3600 [22:38<21:00,  2.00it/s]\n",
            "100% 60/60 [00:06<00:00,  7.41it/s]\u001b[A\n",
            "{'loss': 0.0406, 'grad_norm': 0.06340766698122025, 'learning_rate': 4e-05, 'epoch': 10.0}\n",
            " 33% 1200/3600 [25:28<23:09,  1.73it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 16.12it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05,  9.51it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:06,  8.59it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:06,  8.18it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  7.97it/s]\u001b[A\n",
            " 15% 9/60 [00:01<00:06,  8.08it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:06,  7.90it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:06,  7.59it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:06,  7.25it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:06,  7.22it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:06,  7.14it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:06,  6.99it/s]\u001b[A\n",
            " 27% 16/60 [00:02<00:06,  7.10it/s]\u001b[A\n",
            " 28% 17/60 [00:02<00:05,  7.30it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:04,  8.57it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  9.48it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:03, 10.08it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 10.50it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:03, 10.48it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:02, 10.73it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:02, 10.89it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:02, 10.94it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 10.97it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 11.01it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:01, 10.73it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:01, 10.88it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:01, 11.05it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01, 11.16it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01, 11.17it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:00, 11.20it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:00, 10.80it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00, 10.90it/s]\u001b[A\n",
            " 92% 55/60 [00:05<00:00, 11.03it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00, 11.13it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.026150304824113846, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.6923076923076923, 'eval_EIN_recall': 1.0, 'eval_EIN_f1': 0.8181818181818181, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.6666666666666666, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.8421052631578947, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.744186046511628, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.8333333333333334, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 0.9090909090909091, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.8421052631578947, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8888888888888888, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 1.0, 'eval_SSN_recall': 0.6363636363636364, 'eval_SSN_f1': 0.7777777777777778, 'eval_SSN_number': 11, 'eval_overall_precision': 0.8503937007874016, 'eval_overall_recall': 0.9, 'eval_overall_f1': 0.874493927125506, 'eval_overall_accuracy': 0.9987098855023383, 'eval_runtime': 6.8793, 'eval_samples_per_second': 8.722, 'eval_steps_per_second': 8.722, 'epoch': 10.0}\n",
            " 33% 1200/3600 [25:35<23:09,  1.73it/s]\n",
            "100% 60/60 [00:06<00:00, 11.01it/s]\u001b[A\n",
            "{'loss': 0.0372, 'grad_norm': 0.04293488711118698, 'learning_rate': 4e-05, 'epoch': 11.0}\n",
            " 37% 1320/3600 [28:27<20:47,  1.83it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 16.81it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05, 10.33it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:05,  9.36it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:05,  9.07it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:05,  8.96it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:05,  8.82it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:05,  8.54it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:05,  8.52it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:05,  8.11it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:05,  8.04it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:05,  7.97it/s]\u001b[A\n",
            " 27% 16/60 [00:01<00:05,  7.94it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:04,  8.96it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:04,  9.76it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:03, 10.30it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:03, 10.34it/s]\u001b[A\n",
            " 43% 26/60 [00:02<00:03, 10.63it/s]\u001b[A\n",
            " 47% 28/60 [00:02<00:02, 10.82it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:02, 11.02it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:02, 10.07it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02,  9.16it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02,  9.00it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:02,  8.88it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02,  8.73it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02,  8.64it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:02,  8.51it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:02,  8.41it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:02,  8.31it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:02,  8.14it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:02,  8.16it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01,  8.23it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01,  8.26it/s]\u001b[A\n",
            " 77% 46/60 [00:05<00:01,  8.31it/s]\u001b[A\n",
            " 78% 47/60 [00:05<00:01,  8.23it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01,  8.30it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  8.34it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:01,  8.17it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:01,  7.97it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:00,  8.07it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  8.01it/s]\u001b[A\n",
            " 90% 54/60 [00:06<00:00,  7.97it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00,  7.87it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00,  8.02it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00,  7.90it/s]\u001b[A\n",
            " 97% 58/60 [00:06<00:00,  7.97it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.022556642070412636, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.8333333333333334, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.6666666666666667, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.8695652173913043, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 0.9302325581395349, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.7619047619047619, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8421052631578947, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.6666666666666666, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.7692307692307692, 'eval_SSN_number': 11, 'eval_overall_precision': 0.8661417322834646, 'eval_overall_recall': 0.9166666666666666, 'eval_overall_f1': 0.8906882591093117, 'eval_overall_accuracy': 0.9991533623609096, 'eval_runtime': 7.5498, 'eval_samples_per_second': 7.947, 'eval_steps_per_second': 7.947, 'epoch': 11.0}\n",
            " 37% 1320/3600 [28:35<20:47,  1.83it/s]\n",
            "100% 60/60 [00:07<00:00,  7.74it/s]\u001b[A\n",
            "{'loss': 0.0344, 'grad_norm': 0.05607011914253235, 'learning_rate': 4e-05, 'epoch': 12.0}\n",
            " 40% 1440/3600 [31:26<20:34,  1.75it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 16.58it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05,  9.98it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:06,  8.83it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:06,  8.52it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  7.99it/s]\u001b[A\n",
            " 15% 9/60 [00:01<00:06,  7.59it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:06,  7.54it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:06,  7.19it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:06,  7.18it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:06,  7.22it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:06,  7.23it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:06,  7.14it/s]\u001b[A\n",
            " 27% 16/60 [00:02<00:06,  7.16it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:04,  8.62it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:04,  9.24it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:03,  9.86it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:03, 10.30it/s]\u001b[A\n",
            " 43% 26/60 [00:02<00:03, 10.66it/s]\u001b[A\n",
            " 47% 28/60 [00:03<00:02, 10.83it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:02, 10.95it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:02, 10.90it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02, 11.05it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:02, 11.17it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:01, 11.28it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:01, 11.14it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:01, 11.06it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01, 10.93it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01, 11.06it/s]\u001b[A\n",
            " 80% 48/60 [00:04<00:01, 11.09it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:00, 11.16it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:00, 11.19it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00, 11.31it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00, 10.99it/s]\u001b[A\n",
            " 97% 58/60 [00:05<00:00, 11.00it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.02044537663459778, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.3333333333333333, 'eval_BUSINESS_NAME_recall': 0.5, 'eval_BUSINESS_NAME_f1': 0.4, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.7142857142857143, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.6666666666666666, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.8421052631578947, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.744186046511628, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.8421052631578947, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8888888888888888, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.5625, 'eval_SSN_recall': 0.8181818181818182, 'eval_SSN_f1': 0.6666666666666666, 'eval_SSN_number': 11, 'eval_overall_precision': 0.8307692307692308, 'eval_overall_recall': 0.9, 'eval_overall_f1': 0.8640000000000001, 'eval_overall_accuracy': 0.9991130462828576, 'eval_runtime': 6.8438, 'eval_samples_per_second': 8.767, 'eval_steps_per_second': 8.767, 'epoch': 12.0}\n",
            " 40% 1440/3600 [31:33<20:34,  1.75it/s]\n",
            "100% 60/60 [00:06<00:00, 11.54it/s]\u001b[A\n",
            "{'loss': 0.0323, 'grad_norm': 0.033692359924316406, 'learning_rate': 4e-05, 'epoch': 13.0}\n",
            " 43% 1560/3600 [33:49<17:23,  1.95it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 16.98it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.44it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.11it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.66it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.53it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.43it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:03, 11.39it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 11.18it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 10.87it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 10.85it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:03, 10.99it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 10.93it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:03, 10.97it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:02, 10.74it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:02, 10.76it/s]\u001b[A\n",
            " 55% 33/60 [00:02<00:02, 10.90it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 11.04it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 11.13it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:01, 11.05it/s]\u001b[A\n",
            " 68% 41/60 [00:03<00:01, 10.96it/s]\u001b[A\n",
            " 72% 43/60 [00:03<00:01, 11.01it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01, 11.10it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01, 11.10it/s]\u001b[A\n",
            " 82% 49/60 [00:04<00:00, 11.03it/s]\u001b[A\n",
            " 85% 51/60 [00:04<00:00, 11.05it/s]\u001b[A\n",
            " 88% 53/60 [00:04<00:00, 10.69it/s]\u001b[A\n",
            " 92% 55/60 [00:04<00:00, 10.82it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00, 10.92it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.018203889951109886, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.3333333333333333, 'eval_BUSINESS_NAME_recall': 0.5, 'eval_BUSINESS_NAME_f1': 0.4, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.8333333333333334, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.6666666666666667, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.7619047619047619, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8421052631578947, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.6666666666666666, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.7692307692307692, 'eval_SSN_number': 11, 'eval_overall_precision': 0.8818897637795275, 'eval_overall_recall': 0.9333333333333333, 'eval_overall_f1': 0.9068825910931174, 'eval_overall_accuracy': 0.9993952588292211, 'eval_runtime': 6.362, 'eval_samples_per_second': 9.431, 'eval_steps_per_second': 9.431, 'epoch': 13.0}\n",
            " 43% 1560/3600 [33:56<17:23,  1.95it/s]\n",
            "100% 60/60 [00:06<00:00, 11.00it/s]\u001b[A\n",
            "{'loss': 0.0302, 'grad_norm': 0.062000710517168045, 'learning_rate': 4e-05, 'epoch': 14.0}\n",
            " 47% 1680/3600 [36:46<16:19,  1.96it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 16.36it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.18it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 11.71it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.38it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.32it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.10it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:04, 11.07it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 10.80it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 10.94it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 10.98it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:03, 11.09it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 11.00it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:03, 10.98it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:02, 10.81it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:02, 10.90it/s]\u001b[A\n",
            " 55% 33/60 [00:02<00:02, 11.04it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 11.11it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 11.10it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:01, 10.64it/s]\u001b[A\n",
            " 68% 41/60 [00:03<00:02,  9.46it/s]\u001b[A\n",
            " 70% 42/60 [00:03<00:01,  9.24it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:01,  9.03it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01,  8.87it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01,  8.86it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01,  8.71it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01,  8.47it/s]\u001b[A\n",
            " 80% 48/60 [00:04<00:01,  8.19it/s]\u001b[A\n",
            " 82% 49/60 [00:04<00:01,  7.64it/s]\u001b[A\n",
            " 83% 50/60 [00:04<00:01,  7.41it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:01,  7.46it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:01,  7.41it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  7.47it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00,  7.71it/s]\u001b[A\n",
            " 92% 55/60 [00:05<00:00,  7.90it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00,  8.04it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00,  7.83it/s]\u001b[A\n",
            " 97% 58/60 [00:05<00:00,  7.84it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.017156336456537247, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 1.0, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 1.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.8333333333333334, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.6666666666666667, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.95, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.9743589743589743, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.7619047619047619, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8421052631578947, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.7142857142857143, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.8, 'eval_SSN_number': 11, 'eval_overall_precision': 0.912, 'eval_overall_recall': 0.95, 'eval_overall_f1': 0.9306122448979591, 'eval_overall_accuracy': 0.999475890985325, 'eval_runtime': 7.2418, 'eval_samples_per_second': 8.285, 'eval_steps_per_second': 8.285, 'epoch': 14.0}\n",
            " 47% 1680/3600 [36:53<16:19,  1.96it/s]\n",
            "100% 60/60 [00:07<00:00,  7.92it/s]\u001b[A\n",
            "{'loss': 0.0291, 'grad_norm': 0.03190045803785324, 'learning_rate': 4e-05, 'epoch': 15.0}\n",
            " 50% 1800/3600 [39:25<16:28,  1.82it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:04, 13.92it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:06,  9.02it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:06,  8.37it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:06,  7.99it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:06,  8.00it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  7.83it/s]\u001b[A\n",
            " 15% 9/60 [00:01<00:06,  7.51it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:06,  7.26it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:06,  7.09it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:06,  7.32it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:06,  7.44it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:06,  7.46it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:05,  7.72it/s]\u001b[A\n",
            " 27% 16/60 [00:02<00:05,  7.78it/s]\u001b[A\n",
            " 28% 17/60 [00:02<00:05,  7.92it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:05,  7.74it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:05,  7.39it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:05,  7.47it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:05,  7.60it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  7.78it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  7.79it/s]\u001b[A\n",
            " 40% 24/60 [00:03<00:04,  7.72it/s]\u001b[A\n",
            " 42% 25/60 [00:03<00:04,  7.84it/s]\u001b[A\n",
            " 43% 26/60 [00:03<00:04,  8.01it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:04,  7.76it/s]\u001b[A\n",
            " 47% 28/60 [00:03<00:04,  7.46it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:04,  7.47it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  7.70it/s]\u001b[A\n",
            " 52% 31/60 [00:04<00:03,  7.37it/s]\u001b[A\n",
            " 53% 32/60 [00:04<00:03,  7.49it/s]\u001b[A\n",
            " 55% 33/60 [00:04<00:03,  7.38it/s]\u001b[A\n",
            " 57% 34/60 [00:04<00:03,  7.35it/s]\u001b[A\n",
            " 58% 35/60 [00:04<00:03,  7.47it/s]\u001b[A\n",
            " 60% 36/60 [00:04<00:03,  7.11it/s]\u001b[A\n",
            " 62% 37/60 [00:04<00:03,  7.14it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02,  7.43it/s]\u001b[A\n",
            " 65% 39/60 [00:05<00:03,  6.98it/s]\u001b[A\n",
            " 67% 40/60 [00:05<00:02,  6.71it/s]\u001b[A\n",
            " 68% 41/60 [00:05<00:02,  6.85it/s]\u001b[A\n",
            " 70% 42/60 [00:05<00:02,  7.02it/s]\u001b[A\n",
            " 72% 43/60 [00:05<00:02,  7.20it/s]\u001b[A\n",
            " 75% 45/60 [00:05<00:01,  8.56it/s]\u001b[A\n",
            " 78% 47/60 [00:06<00:01,  9.45it/s]\u001b[A\n",
            " 82% 49/60 [00:06<00:01,  9.95it/s]\u001b[A\n",
            " 85% 51/60 [00:06<00:00, 10.31it/s]\u001b[A\n",
            " 88% 53/60 [00:06<00:00, 10.59it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00, 10.43it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00, 10.66it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.01594933494925499, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 1.0, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 1.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.7142857142857143, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.6250000000000001, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.8, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8648648648648648, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.5625, 'eval_SSN_recall': 0.8181818181818182, 'eval_SSN_f1': 0.6666666666666666, 'eval_SSN_number': 11, 'eval_overall_precision': 0.8968253968253969, 'eval_overall_recall': 0.9416666666666667, 'eval_overall_f1': 0.9186991869918699, 'eval_overall_accuracy': 0.9993952588292211, 'eval_runtime': 8.1074, 'eval_samples_per_second': 7.401, 'eval_steps_per_second': 7.401, 'epoch': 15.0}\n",
            " 50% 1800/3600 [39:33<16:28,  1.82it/s]\n",
            "100% 60/60 [00:07<00:00, 10.74it/s]\u001b[A\n",
            "{'loss': 0.0286, 'grad_norm': 0.042778968811035156, 'learning_rate': 4e-05, 'epoch': 16.0}\n",
            " 53% 1920/3600 [42:31<14:09,  1.98it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 16.78it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.44it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.39it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.77it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.59it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.44it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:03, 11.40it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 10.88it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 10.87it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03,  9.77it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  9.41it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  9.17it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:04,  8.95it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:04,  8.73it/s]\u001b[A\n",
            " 43% 26/60 [00:02<00:04,  8.42it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:04,  8.25it/s]\u001b[A\n",
            " 47% 28/60 [00:02<00:03,  8.02it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:03,  7.91it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  7.89it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:03,  8.06it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:03,  7.90it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:03,  7.93it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:03,  7.89it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:03,  7.83it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:03,  7.96it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02,  8.07it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02,  7.95it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:02,  7.94it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:02,  8.05it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:02,  8.01it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:02,  8.10it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:02,  7.79it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:02,  7.86it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01,  7.85it/s]\u001b[A\n",
            " 77% 46/60 [00:05<00:01,  7.88it/s]\u001b[A\n",
            " 78% 47/60 [00:05<00:01,  7.74it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01,  7.83it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  7.79it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:01,  7.78it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:00,  8.38it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  8.17it/s]\u001b[A\n",
            " 90% 54/60 [00:06<00:00,  8.14it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00,  8.14it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00,  7.92it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00,  7.75it/s]\u001b[A\n",
            " 97% 58/60 [00:06<00:00,  7.74it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.01629789173603058, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 1.0, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 1.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.9523809523809523, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.975609756097561, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.47368421052631576, 'eval_EIN_recall': 1.0, 'eval_EIN_f1': 0.6428571428571429, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.7272727272727273, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.8421052631578947, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.7804878048780488, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.7272727272727273, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8205128205128205, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.0, 'eval_SSN_recall': 0.0, 'eval_SSN_f1': 0.0, 'eval_SSN_number': 11, 'eval_overall_precision': 0.7608695652173914, 'eval_overall_recall': 0.875, 'eval_overall_f1': 0.813953488372093, 'eval_overall_accuracy': 0.998306724721819, 'eval_runtime': 7.7777, 'eval_samples_per_second': 7.714, 'eval_steps_per_second': 7.714, 'epoch': 16.0}\n",
            " 53% 1920/3600 [42:39<14:09,  1.98it/s]\n",
            "100% 60/60 [00:07<00:00,  7.89it/s]\u001b[A\n",
            "{'loss': 0.0282, 'grad_norm': 0.02785344235599041, 'learning_rate': 4e-05, 'epoch': 17.0}\n",
            " 57% 2040/3600 [45:24<13:03,  1.99it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 16.60it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.26it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.36it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.90it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.51it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.43it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:03, 11.35it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:04,  9.98it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:04,  9.28it/s]\u001b[A\n",
            " 33% 20/60 [00:01<00:04,  9.05it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  8.78it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  8.62it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  8.36it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:04,  7.89it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:04,  7.66it/s]\u001b[A\n",
            " 43% 26/60 [00:02<00:04,  7.55it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:04,  7.53it/s]\u001b[A\n",
            " 47% 28/60 [00:02<00:04,  7.56it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:04,  7.60it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  7.50it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:03,  7.59it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:03,  7.71it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:03,  7.87it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:03,  7.97it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:03,  8.02it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:02,  8.02it/s]\u001b[A\n",
            " 62% 37/60 [00:04<00:02,  8.13it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02,  7.99it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:02,  7.80it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:02,  7.63it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:02,  7.65it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:02,  7.72it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:02,  7.56it/s]\u001b[A\n",
            " 73% 44/60 [00:05<00:02,  7.59it/s]\u001b[A\n",
            " 75% 45/60 [00:05<00:01,  7.55it/s]\u001b[A\n",
            " 77% 46/60 [00:05<00:01,  7.58it/s]\u001b[A\n",
            " 78% 47/60 [00:05<00:01,  7.20it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01,  7.34it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  7.61it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:01,  7.80it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:01,  7.66it/s]\u001b[A\n",
            " 87% 52/60 [00:06<00:01,  7.76it/s]\u001b[A\n",
            " 88% 53/60 [00:06<00:00,  7.76it/s]\u001b[A\n",
            " 90% 54/60 [00:06<00:00,  7.92it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00,  7.80it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00,  7.50it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00,  7.37it/s]\u001b[A\n",
            " 97% 58/60 [00:06<00:00,  7.34it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.015964452177286148, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.0, 'eval_BUSINESS_NAME_recall': 0.0, 'eval_BUSINESS_NAME_f1': 0.0, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.7142857142857143, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.8, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 0.888888888888889, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 1.0, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9696969696969697, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.6666666666666666, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.7692307692307692, 'eval_SSN_number': 11, 'eval_overall_precision': 0.88, 'eval_overall_recall': 0.9166666666666666, 'eval_overall_f1': 0.8979591836734694, 'eval_overall_accuracy': 0.9991533623609096, 'eval_runtime': 8.1299, 'eval_samples_per_second': 7.38, 'eval_steps_per_second': 7.38, 'epoch': 17.0}\n",
            " 57% 2040/3600 [45:32<13:03,  1.99it/s]\n",
            "100% 60/60 [00:08<00:00,  7.53it/s]\u001b[A\n",
            "{'loss': 0.0252, 'grad_norm': 0.02777235209941864, 'learning_rate': 4e-05, 'epoch': 18.0}\n",
            " 60% 2160/3600 [48:08<12:58,  1.85it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 16.28it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.25it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.40it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.83it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.54it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.20it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:04, 11.20it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 11.14it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 11.10it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 11.07it/s]\u001b[A\n",
            " 38% 23/60 [00:01<00:03, 11.11it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 10.91it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:03, 10.78it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:02, 10.91it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:02, 10.87it/s]\u001b[A\n",
            " 55% 33/60 [00:02<00:02, 10.96it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 11.05it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 10.72it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:01, 10.80it/s]\u001b[A\n",
            " 68% 41/60 [00:03<00:01, 10.85it/s]\u001b[A\n",
            " 72% 43/60 [00:03<00:01, 10.95it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01, 11.00it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01, 11.00it/s]\u001b[A\n",
            " 82% 49/60 [00:04<00:00, 11.06it/s]\u001b[A\n",
            " 85% 51/60 [00:04<00:00, 11.07it/s]\u001b[A\n",
            " 88% 53/60 [00:04<00:00, 11.12it/s]\u001b[A\n",
            " 92% 55/60 [00:04<00:00, 11.18it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00, 11.21it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.013027234002947807, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.75, 'eval_BUSINESS_NAME_recall': 0.75, 'eval_BUSINESS_NAME_f1': 0.75, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.8333333333333334, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.6666666666666667, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.8888888888888888, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9142857142857143, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.6666666666666666, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.7692307692307692, 'eval_SSN_number': 11, 'eval_overall_precision': 0.9262295081967213, 'eval_overall_recall': 0.9416666666666667, 'eval_overall_f1': 0.9338842975206612, 'eval_overall_accuracy': 0.9991936784389615, 'eval_runtime': 6.0039, 'eval_samples_per_second': 9.994, 'eval_steps_per_second': 9.994, 'epoch': 18.0}\n",
            " 60% 2160/3600 [48:14<12:58,  1.85it/s]\n",
            "100% 60/60 [00:05<00:00, 10.85it/s]\u001b[A\n",
            "{'loss': 0.0238, 'grad_norm': 0.017206666991114616, 'learning_rate': 4e-05, 'epoch': 19.0}\n",
            " 63% 2280/3600 [50:42<11:37,  1.89it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:04, 13.89it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05,  9.74it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:06,  8.52it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:06,  8.22it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  7.81it/s]\u001b[A\n",
            " 15% 9/60 [00:01<00:06,  7.89it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:06,  7.98it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:06,  7.90it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:06,  7.84it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:06,  7.59it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:06,  7.56it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:06,  7.45it/s]\u001b[A\n",
            " 27% 16/60 [00:02<00:05,  7.35it/s]\u001b[A\n",
            " 28% 17/60 [00:02<00:05,  7.35it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:05,  7.55it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:05,  7.62it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:05,  7.67it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  7.91it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  8.08it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  8.01it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:04,  8.14it/s]\u001b[A\n",
            " 42% 25/60 [00:03<00:04,  8.10it/s]\u001b[A\n",
            " 43% 26/60 [00:03<00:04,  7.77it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:04,  7.94it/s]\u001b[A\n",
            " 47% 28/60 [00:03<00:03,  8.13it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:03,  8.22it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  8.26it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:03,  8.26it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:03,  8.06it/s]\u001b[A\n",
            " 55% 33/60 [00:04<00:03,  7.76it/s]\u001b[A\n",
            " 57% 34/60 [00:04<00:03,  7.79it/s]\u001b[A\n",
            " 58% 35/60 [00:04<00:03,  7.63it/s]\u001b[A\n",
            " 60% 36/60 [00:04<00:03,  7.32it/s]\u001b[A\n",
            " 62% 37/60 [00:04<00:03,  6.81it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:03,  6.88it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:02,  7.08it/s]\u001b[A\n",
            " 67% 40/60 [00:05<00:02,  7.20it/s]\u001b[A\n",
            " 68% 41/60 [00:05<00:02,  7.30it/s]\u001b[A\n",
            " 70% 42/60 [00:05<00:02,  6.96it/s]\u001b[A\n",
            " 72% 43/60 [00:05<00:02,  7.30it/s]\u001b[A\n",
            " 73% 44/60 [00:05<00:02,  7.43it/s]\u001b[A\n",
            " 75% 45/60 [00:05<00:01,  7.62it/s]\u001b[A\n",
            " 77% 46/60 [00:05<00:01,  7.64it/s]\u001b[A\n",
            " 78% 47/60 [00:06<00:01,  7.55it/s]\u001b[A\n",
            " 82% 49/60 [00:06<00:01,  8.95it/s]\u001b[A\n",
            " 85% 51/60 [00:06<00:00,  9.74it/s]\u001b[A\n",
            " 87% 52/60 [00:06<00:00,  9.58it/s]\u001b[A\n",
            " 90% 54/60 [00:06<00:00, 10.20it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00, 10.59it/s]\u001b[A\n",
            " 97% 58/60 [00:07<00:00, 10.72it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.012790500186383724, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.3333333333333333, 'eval_BUSINESS_NAME_recall': 0.5, 'eval_BUSINESS_NAME_f1': 0.4, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.9090909090909091, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.9523809523809523, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.8333333333333334, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.6666666666666667, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.8095238095238095, 'eval_LIST_ACCOUNT_NUMBER_recall': 0.8947368421052632, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.8500000000000001, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 1.0, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9696969696969697, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.6666666666666666, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.7692307692307692, 'eval_SSN_number': 11, 'eval_overall_precision': 0.873015873015873, 'eval_overall_recall': 0.9166666666666666, 'eval_overall_f1': 0.894308943089431, 'eval_overall_accuracy': 0.9993146266731172, 'eval_runtime': 8.0422, 'eval_samples_per_second': 7.461, 'eval_steps_per_second': 7.461, 'epoch': 19.0}\n",
            " 63% 2280/3600 [50:50<11:37,  1.89it/s]\n",
            "100% 60/60 [00:07<00:00, 11.33it/s]\u001b[A\n",
            "{'loss': 0.0234, 'grad_norm': 0.016668153926730156, 'learning_rate': 4e-05, 'epoch': 20.0}\n",
            " 67% 2400/3600 [53:52<10:05,  1.98it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 16.65it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.53it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.27it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.68it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.41it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 10.96it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:04, 10.84it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:04,  9.78it/s]\u001b[A\n",
            " 30% 18/60 [00:01<00:04,  9.41it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:04,  9.05it/s]\u001b[A\n",
            " 33% 20/60 [00:01<00:04,  8.79it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  8.64it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  7.93it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  7.97it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:04,  7.94it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:04,  7.85it/s]\u001b[A\n",
            " 43% 26/60 [00:02<00:04,  7.85it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:04,  7.96it/s]\u001b[A\n",
            " 47% 28/60 [00:02<00:03,  8.07it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:03,  7.92it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  7.58it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:03,  7.37it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:03,  7.49it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:03,  7.68it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:03,  7.41it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:03,  7.48it/s]\u001b[A\n",
            " 60% 36/60 [00:04<00:03,  7.20it/s]\u001b[A\n",
            " 62% 37/60 [00:04<00:03,  7.25it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02,  7.52it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:02,  7.38it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:02,  7.20it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:02,  7.27it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:02,  7.44it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:02,  7.43it/s]\u001b[A\n",
            " 73% 44/60 [00:05<00:02,  7.62it/s]\u001b[A\n",
            " 75% 45/60 [00:05<00:01,  7.64it/s]\u001b[A\n",
            " 77% 46/60 [00:05<00:01,  7.64it/s]\u001b[A\n",
            " 78% 47/60 [00:05<00:01,  7.16it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01,  6.95it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  7.09it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:01,  7.07it/s]\u001b[A\n",
            " 85% 51/60 [00:06<00:01,  7.06it/s]\u001b[A\n",
            " 87% 52/60 [00:06<00:01,  7.15it/s]\u001b[A\n",
            " 88% 53/60 [00:06<00:00,  7.29it/s]\u001b[A\n",
            " 90% 54/60 [00:06<00:00,  7.30it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00,  7.04it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00,  7.29it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00,  7.31it/s]\u001b[A\n",
            " 97% 58/60 [00:07<00:00,  7.58it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.01226691622287035, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.42857142857142855, 'eval_BUSINESS_NAME_recall': 0.75, 'eval_BUSINESS_NAME_f1': 0.5454545454545454, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.7142857142857143, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 1.0, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9696969696969697, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.6666666666666666, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.7692307692307692, 'eval_SSN_number': 11, 'eval_overall_precision': 0.9262295081967213, 'eval_overall_recall': 0.9416666666666667, 'eval_overall_f1': 0.9338842975206612, 'eval_overall_accuracy': 0.9993146266731172, 'eval_runtime': 8.1683, 'eval_samples_per_second': 7.345, 'eval_steps_per_second': 7.345, 'epoch': 20.0}\n",
            " 67% 2400/3600 [54:01<10:05,  1.98it/s]\n",
            "100% 60/60 [00:08<00:00,  7.69it/s]\u001b[A\n",
            "{'loss': 0.0219, 'grad_norm': 0.02510572038590908, 'learning_rate': 4e-05, 'epoch': 21.0}\n",
            " 70% 2520/3600 [56:51<10:01,  1.80it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 15.84it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05, 10.11it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:05,  9.13it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:05,  8.90it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  8.44it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:06,  8.38it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:06,  8.19it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:06,  8.07it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:05,  9.20it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:04,  9.48it/s]\u001b[A\n",
            " 27% 16/60 [00:01<00:04,  9.11it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:04,  8.84it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:04,  8.66it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:04,  8.56it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:04,  8.48it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  8.23it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  8.22it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  7.90it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:04,  7.83it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:04,  7.78it/s]\u001b[A\n",
            " 43% 26/60 [00:03<00:04,  7.37it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:04,  6.84it/s]\u001b[A\n",
            " 47% 28/60 [00:03<00:04,  7.15it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:04,  7.40it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  7.53it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:03,  7.66it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:03,  7.77it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:03,  7.84it/s]\u001b[A\n",
            " 57% 34/60 [00:04<00:03,  7.53it/s]\u001b[A\n",
            " 58% 35/60 [00:04<00:03,  7.68it/s]\u001b[A\n",
            " 60% 36/60 [00:04<00:03,  7.84it/s]\u001b[A\n",
            " 62% 37/60 [00:04<00:02,  7.93it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02,  7.90it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:02,  8.00it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:02,  7.85it/s]\u001b[A\n",
            " 68% 41/60 [00:05<00:02,  7.72it/s]\u001b[A\n",
            " 70% 42/60 [00:05<00:02,  7.61it/s]\u001b[A\n",
            " 72% 43/60 [00:05<00:02,  7.63it/s]\u001b[A\n",
            " 73% 44/60 [00:05<00:02,  7.62it/s]\u001b[A\n",
            " 75% 45/60 [00:05<00:01,  7.61it/s]\u001b[A\n",
            " 78% 47/60 [00:05<00:01,  8.86it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  9.61it/s]\u001b[A\n",
            " 85% 51/60 [00:06<00:00, 10.17it/s]\u001b[A\n",
            " 88% 53/60 [00:06<00:00, 10.22it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00, 10.36it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00, 10.45it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.011452929116785526, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 1.0, 'eval_EIN_f1': 1.0, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 1.0, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9696969696969697, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.9090909090909091, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.9090909090909091, 'eval_SSN_number': 11, 'eval_overall_precision': 0.9833333333333333, 'eval_overall_recall': 0.9833333333333333, 'eval_overall_f1': 0.9833333333333333, 'eval_overall_accuracy': 0.9993549427511692, 'eval_runtime': 7.7367, 'eval_samples_per_second': 7.755, 'eval_steps_per_second': 7.755, 'epoch': 21.0}\n",
            " 70% 2520/3600 [56:59<10:01,  1.80it/s]\n",
            "100% 60/60 [00:07<00:00, 10.65it/s]\u001b[A\n",
            "{'loss': 0.02, 'grad_norm': 0.0415298230946064, 'learning_rate': 4e-05, 'epoch': 22.0}\n",
            " 73% 2640/3600 [1:00:04<08:08,  1.96it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 16.96it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.16it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 11.57it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.05it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 10.78it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 10.78it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:04, 10.82it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:04, 10.64it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 10.82it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 10.89it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:03, 11.03it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 11.02it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:02, 11.08it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:03,  9.84it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:03,  9.30it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:03,  9.03it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:03,  8.86it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02,  8.73it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02,  8.66it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:02,  8.53it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02,  8.16it/s]\u001b[A\n",
            " 63% 38/60 [00:03<00:02,  7.79it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:02,  7.81it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:02,  7.91it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:02,  8.01it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:02,  7.86it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:02,  7.97it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:02,  7.74it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01,  7.79it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01,  7.69it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01,  7.75it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01,  7.65it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  7.49it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:01,  7.52it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:01,  7.06it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:01,  7.20it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  7.35it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00,  7.30it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00,  7.59it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00,  7.79it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00,  7.89it/s]\u001b[A\n",
            " 97% 58/60 [00:06<00:00,  7.64it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.012228677980601788, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.9523809523809523, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.975609756097561, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.6666666666666666, 'eval_EIN_f1': 0.8, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 1.0, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9696969696969697, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.7142857142857143, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.8, 'eval_SSN_number': 11, 'eval_overall_precision': 0.9504132231404959, 'eval_overall_recall': 0.9583333333333334, 'eval_overall_f1': 0.9543568464730291, 'eval_overall_accuracy': 0.9993549427511692, 'eval_runtime': 7.7586, 'eval_samples_per_second': 7.733, 'eval_steps_per_second': 7.733, 'epoch': 22.0}\n",
            " 73% 2640/3600 [1:00:12<08:08,  1.96it/s]\n",
            "100% 60/60 [00:07<00:00,  7.49it/s]\u001b[A\n",
            "{'loss': 0.0209, 'grad_norm': 0.015899773687124252, 'learning_rate': 4e-05, 'epoch': 23.0}\n",
            " 77% 2760/3600 [1:03:02<07:05,  1.97it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 15.53it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.07it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 11.80it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.56it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.31it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.13it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:04, 10.94it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:04, 10.66it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 10.65it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 10.79it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:03, 10.80it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 10.90it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:03, 10.88it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:03, 10.27it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:03,  9.54it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:03,  9.28it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:02,  9.02it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02,  8.70it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02,  8.61it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:02,  8.31it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02,  7.93it/s]\u001b[A\n",
            " 63% 38/60 [00:03<00:02,  7.64it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:02,  7.19it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:02,  6.93it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:02,  6.97it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:02,  7.29it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:02,  7.50it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:02,  7.57it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01,  7.51it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01,  7.73it/s]\u001b[A\n",
            " 78% 47/60 [00:05<00:01,  7.53it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01,  7.72it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  7.68it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:01,  7.90it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:01,  7.64it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:01,  7.61it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  7.14it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00,  7.09it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00,  7.16it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00,  7.05it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00,  6.91it/s]\u001b[A\n",
            " 97% 58/60 [00:06<00:00,  6.54it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.010182037949562073, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.8571428571428571, 'eval_EIN_recall': 0.6666666666666666, 'eval_EIN_f1': 0.75, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 1.0, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9696969696969697, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.7142857142857143, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.8, 'eval_SSN_number': 11, 'eval_overall_precision': 0.9504132231404959, 'eval_overall_recall': 0.9583333333333334, 'eval_overall_f1': 0.9543568464730291, 'eval_overall_accuracy': 0.9993952588292211, 'eval_runtime': 7.958, 'eval_samples_per_second': 7.54, 'eval_steps_per_second': 7.54, 'epoch': 23.0}\n",
            " 77% 2760/3600 [1:03:10<07:05,  1.97it/s]\n",
            "100% 60/60 [00:07<00:00,  6.66it/s]\u001b[A\n",
            "{'loss': 0.0187, 'grad_norm': 0.017704468220472336, 'learning_rate': 4e-05, 'epoch': 24.0}\n",
            " 80% 2880/3600 [1:06:08<07:05,  1.69it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 15.87it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05,  9.79it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:05, 10.38it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:04, 10.61it/s]\u001b[A\n",
            " 17% 10/60 [00:00<00:04, 10.77it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:04, 10.71it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:04, 10.86it/s]\u001b[A\n",
            " 27% 16/60 [00:01<00:04, 10.42it/s]\u001b[A\n",
            " 30% 18/60 [00:01<00:03, 10.67it/s]\u001b[A\n",
            " 33% 20/60 [00:01<00:03, 10.72it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:03, 10.85it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:03, 10.86it/s]\u001b[A\n",
            " 43% 26/60 [00:02<00:03, 10.93it/s]\u001b[A\n",
            " 47% 28/60 [00:02<00:03, 10.53it/s]\u001b[A\n",
            " 50% 30/60 [00:02<00:02, 10.70it/s]\u001b[A\n",
            " 53% 32/60 [00:02<00:02, 10.72it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02, 10.86it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:02, 11.00it/s]\u001b[A\n",
            " 63% 38/60 [00:03<00:02, 10.87it/s]\u001b[A\n",
            " 67% 40/60 [00:03<00:01, 10.92it/s]\u001b[A\n",
            " 70% 42/60 [00:03<00:01, 10.96it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01, 11.09it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01, 11.07it/s]\u001b[A\n",
            " 80% 48/60 [00:04<00:01, 10.90it/s]\u001b[A\n",
            " 83% 50/60 [00:04<00:00, 10.78it/s]\u001b[A\n",
            " 87% 52/60 [00:04<00:00, 10.74it/s]\u001b[A\n",
            " 90% 54/60 [00:04<00:00, 10.91it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00, 11.03it/s]\u001b[A\n",
            " 97% 58/60 [00:05<00:00, 10.98it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.010013998486101627, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.7142857142857143, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 1.0, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9696969696969697, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.6666666666666666, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.7692307692307692, 'eval_SSN_number': 11, 'eval_overall_precision': 0.95, 'eval_overall_recall': 0.95, 'eval_overall_f1': 0.9500000000000001, 'eval_overall_accuracy': 0.9993952588292211, 'eval_runtime': 6.3447, 'eval_samples_per_second': 9.457, 'eval_steps_per_second': 9.457, 'epoch': 24.0}\n",
            " 80% 2880/3600 [1:06:15<07:05,  1.69it/s]\n",
            "100% 60/60 [00:06<00:00, 11.52it/s]\u001b[A\n",
            "{'loss': 0.0181, 'grad_norm': 0.013459407724440098, 'learning_rate': 4e-05, 'epoch': 25.0}\n",
            " 83% 3000/3600 [1:08:55<05:02,  1.99it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 17.00it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:04, 13.72it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.57it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.94it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.80it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.64it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:03, 11.62it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 11.12it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 11.03it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 11.16it/s]\u001b[A\n",
            " 38% 23/60 [00:01<00:03, 11.20it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 11.27it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:02, 11.10it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:02, 10.94it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:02, 11.08it/s]\u001b[A\n",
            " 55% 33/60 [00:02<00:02, 11.12it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 10.50it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02,  9.65it/s]\u001b[A\n",
            " 63% 38/60 [00:03<00:02,  9.23it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:02,  8.78it/s]\u001b[A\n",
            " 67% 40/60 [00:03<00:02,  8.73it/s]\u001b[A\n",
            " 68% 41/60 [00:03<00:02,  8.59it/s]\u001b[A\n",
            " 70% 42/60 [00:03<00:02,  8.54it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:02,  8.40it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01,  8.28it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01,  8.24it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01,  8.13it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01,  7.92it/s]\u001b[A\n",
            " 80% 48/60 [00:04<00:01,  8.07it/s]\u001b[A\n",
            " 82% 49/60 [00:04<00:01,  8.17it/s]\u001b[A\n",
            " 83% 50/60 [00:04<00:01,  8.01it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:01,  8.16it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:00,  8.23it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  8.17it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00,  8.08it/s]\u001b[A\n",
            " 92% 55/60 [00:05<00:00,  8.03it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00,  7.66it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00,  7.80it/s]\u001b[A\n",
            " 97% 58/60 [00:05<00:00,  7.94it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.008841726928949356, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.6666666666666666, 'eval_EIN_f1': 0.8, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.95, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.9743589743589743, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.9411764705882353, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9411764705882353, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.75, 'eval_SSN_recall': 0.8181818181818182, 'eval_SSN_f1': 0.7826086956521738, 'eval_SSN_number': 11, 'eval_overall_precision': 0.95, 'eval_overall_recall': 0.95, 'eval_overall_f1': 0.9500000000000001, 'eval_overall_accuracy': 0.9993549427511692, 'eval_runtime': 6.9552, 'eval_samples_per_second': 8.627, 'eval_steps_per_second': 8.627, 'epoch': 25.0}\n",
            " 83% 3000/3600 [1:09:02<05:02,  1.99it/s]\n",
            "100% 60/60 [00:06<00:00,  8.19it/s]\u001b[A\n",
            "{'loss': 0.0201, 'grad_norm': 0.015844978392124176, 'learning_rate': 4e-05, 'epoch': 26.0}\n",
            " 87% 3120/3600 [1:11:53<04:01,  1.99it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 16.85it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05, 10.48it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:05,  9.59it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:05,  9.06it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:05,  8.88it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:05,  8.46it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:05,  8.41it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:05,  8.39it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:05,  8.39it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:05,  8.36it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:05,  8.35it/s]\u001b[A\n",
            " 27% 16/60 [00:01<00:05,  8.42it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:05,  8.14it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:05,  8.23it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:05,  8.00it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:05,  7.66it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:04,  7.86it/s]\u001b[A\n",
            " 37% 22/60 [00:02<00:04,  8.01it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  8.02it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:04,  8.02it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:04,  8.02it/s]\u001b[A\n",
            " 43% 26/60 [00:03<00:04,  7.70it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:04,  7.64it/s]\u001b[A\n",
            " 47% 28/60 [00:03<00:04,  7.77it/s]\u001b[A\n",
            " 48% 29/60 [00:03<00:04,  7.75it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  7.76it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:03,  9.02it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02,  9.86it/s]\u001b[A\n",
            " 60% 36/60 [00:04<00:02, 10.39it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02, 10.21it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:01, 10.54it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:01, 10.68it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01, 10.90it/s]\u001b[A\n",
            " 77% 46/60 [00:05<00:01, 11.05it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01, 10.96it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:00, 11.05it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:00, 11.09it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00, 11.22it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00, 11.29it/s]\u001b[A\n",
            " 97% 58/60 [00:06<00:00, 11.25it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.00769647303968668, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.7142857142857143, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.8, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8648648648648648, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.625, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.7407407407407406, 'eval_SSN_number': 11, 'eval_overall_precision': 0.912, 'eval_overall_recall': 0.95, 'eval_overall_f1': 0.9306122448979591, 'eval_overall_accuracy': 0.9993952588292211, 'eval_runtime': 6.9923, 'eval_samples_per_second': 8.581, 'eval_steps_per_second': 8.581, 'epoch': 26.0}\n",
            " 87% 3120/3600 [1:12:00<04:01,  1.99it/s]\n",
            "100% 60/60 [00:06<00:00, 11.72it/s]\u001b[A\n",
            "{'loss': 0.0186, 'grad_norm': 0.017943505197763443, 'learning_rate': 4e-05, 'epoch': 27.0}\n",
            " 90% 3240/3600 [1:14:37<03:12,  1.87it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 16.84it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05, 10.44it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:05,  9.33it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:05,  8.87it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:05,  8.53it/s]\u001b[A\n",
            " 17% 10/60 [00:01<00:05,  8.49it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:05,  8.44it/s]\u001b[A\n",
            " 20% 12/60 [00:01<00:05,  8.42it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:05,  8.43it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:05,  8.05it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:05,  7.99it/s]\u001b[A\n",
            " 27% 16/60 [00:01<00:05,  8.00it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:05,  7.95it/s]\u001b[A\n",
            " 30% 18/60 [00:02<00:05,  7.78it/s]\u001b[A\n",
            " 32% 19/60 [00:02<00:05,  7.79it/s]\u001b[A\n",
            " 33% 20/60 [00:02<00:05,  7.55it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:05,  7.58it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:04,  8.88it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03,  9.61it/s]\u001b[A\n",
            " 45% 27/60 [00:03<00:03, 10.16it/s]\u001b[A\n",
            " 47% 28/60 [00:03<00:03, 10.01it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:02, 10.50it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:02, 10.73it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02, 10.82it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:02, 10.95it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02, 10.92it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:01, 10.97it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:01, 10.94it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01, 10.86it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01, 10.71it/s]\u001b[A\n",
            " 80% 48/60 [00:04<00:01, 10.62it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:00, 10.65it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:00, 10.74it/s]\u001b[A\n",
            " 90% 54/60 [00:05<00:00, 10.67it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00, 10.78it/s]\u001b[A\n",
            " 97% 58/60 [00:05<00:00, 10.90it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.007727420888841152, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.9523809523809523, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 0.975609756097561, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.6666666666666666, 'eval_EIN_f1': 0.8, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.9411764705882353, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9411764705882353, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.7142857142857143, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.8, 'eval_SSN_number': 11, 'eval_overall_precision': 0.9426229508196722, 'eval_overall_recall': 0.9583333333333334, 'eval_overall_f1': 0.950413223140496, 'eval_overall_accuracy': 0.9993952588292211, 'eval_runtime': 7.0519, 'eval_samples_per_second': 8.508, 'eval_steps_per_second': 8.508, 'epoch': 27.0}\n",
            " 90% 3240/3600 [1:14:44<03:12,  1.87it/s]\n",
            "100% 60/60 [00:06<00:00, 11.26it/s]\u001b[A\n",
            "{'loss': 0.0162, 'grad_norm': 0.06863898783922195, 'learning_rate': 4e-05, 'epoch': 28.0}\n",
            " 93% 3360/3600 [1:17:29<02:13,  1.79it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 16.55it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:05,  9.90it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:06,  8.77it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:06,  8.61it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:06,  8.30it/s]\u001b[A\n",
            " 15% 9/60 [00:01<00:06,  8.11it/s]\u001b[A\n",
            " 18% 11/60 [00:01<00:05,  9.26it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:05,  9.36it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:04,  9.93it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:04, 10.22it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 10.57it/s]\u001b[A\n",
            " 35% 21/60 [00:02<00:03, 10.72it/s]\u001b[A\n",
            " 38% 23/60 [00:02<00:03, 10.83it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 10.84it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:03, 10.61it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:03,  9.52it/s]\u001b[A\n",
            " 50% 30/60 [00:03<00:03,  9.25it/s]\u001b[A\n",
            " 52% 31/60 [00:03<00:03,  8.99it/s]\u001b[A\n",
            " 53% 32/60 [00:03<00:03,  8.67it/s]\u001b[A\n",
            " 55% 33/60 [00:03<00:03,  8.41it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:03,  7.90it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:03,  7.84it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:03,  7.74it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02,  7.83it/s]\u001b[A\n",
            " 63% 38/60 [00:04<00:02,  7.55it/s]\u001b[A\n",
            " 65% 39/60 [00:04<00:02,  7.75it/s]\u001b[A\n",
            " 67% 40/60 [00:04<00:02,  7.91it/s]\u001b[A\n",
            " 68% 41/60 [00:04<00:02,  7.84it/s]\u001b[A\n",
            " 70% 42/60 [00:04<00:02,  7.99it/s]\u001b[A\n",
            " 72% 43/60 [00:04<00:02,  8.13it/s]\u001b[A\n",
            " 73% 44/60 [00:04<00:01,  8.16it/s]\u001b[A\n",
            " 75% 45/60 [00:04<00:01,  8.21it/s]\u001b[A\n",
            " 77% 46/60 [00:05<00:01,  8.06it/s]\u001b[A\n",
            " 78% 47/60 [00:05<00:01,  8.10it/s]\u001b[A\n",
            " 80% 48/60 [00:05<00:01,  8.21it/s]\u001b[A\n",
            " 82% 49/60 [00:05<00:01,  8.37it/s]\u001b[A\n",
            " 83% 50/60 [00:05<00:01,  8.29it/s]\u001b[A\n",
            " 85% 51/60 [00:05<00:01,  8.20it/s]\u001b[A\n",
            " 87% 52/60 [00:05<00:00,  8.16it/s]\u001b[A\n",
            " 88% 53/60 [00:05<00:00,  7.90it/s]\u001b[A\n",
            " 90% 54/60 [00:06<00:00,  8.05it/s]\u001b[A\n",
            " 92% 55/60 [00:06<00:00,  8.00it/s]\u001b[A\n",
            " 93% 56/60 [00:06<00:00,  7.93it/s]\u001b[A\n",
            " 95% 57/60 [00:06<00:00,  7.77it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.011069042608141899, 'eval_ADDRESS_precision': 0.8333333333333334, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 0.9090909090909091, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 0.21875, 'eval_CITY_STATE_ZIP_CODE_recall': 0.35, 'eval_CITY_STATE_ZIP_CODE_f1': 0.2692307692307692, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 1.0, 'eval_EIN_recall': 0.5555555555555556, 'eval_EIN_f1': 0.7142857142857143, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 0.6060606060606061, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 0.7547169811320755, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.8421052631578947, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8888888888888888, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.625, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.7407407407407406, 'eval_SSN_number': 11, 'eval_overall_precision': 0.6601307189542484, 'eval_overall_recall': 0.8416666666666667, 'eval_overall_f1': 0.7399267399267399, 'eval_overall_accuracy': 0.9979438800193517, 'eval_runtime': 7.4629, 'eval_samples_per_second': 8.04, 'eval_steps_per_second': 8.04, 'epoch': 28.0}\n",
            " 93% 3360/3600 [1:17:36<02:13,  1.79it/s]\n",
            "100% 60/60 [00:07<00:00,  8.98it/s]\u001b[A\n",
            "{'loss': 0.0163, 'grad_norm': 0.025726545602083206, 'learning_rate': 4e-05, 'epoch': 29.0}\n",
            " 97% 3480/3600 [1:20:21<01:00,  1.99it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 3/60 [00:00<00:03, 17.02it/s]\u001b[A\n",
            "  8% 5/60 [00:00<00:03, 13.84it/s]\u001b[A\n",
            " 12% 7/60 [00:00<00:04, 12.45it/s]\u001b[A\n",
            " 15% 9/60 [00:00<00:04, 11.93it/s]\u001b[A\n",
            " 18% 11/60 [00:00<00:04, 11.71it/s]\u001b[A\n",
            " 22% 13/60 [00:01<00:04, 11.36it/s]\u001b[A\n",
            " 25% 15/60 [00:01<00:03, 11.36it/s]\u001b[A\n",
            " 28% 17/60 [00:01<00:03, 11.23it/s]\u001b[A\n",
            " 32% 19/60 [00:01<00:03, 11.28it/s]\u001b[A\n",
            " 35% 21/60 [00:01<00:03, 11.29it/s]\u001b[A\n",
            " 38% 23/60 [00:01<00:03, 11.31it/s]\u001b[A\n",
            " 42% 25/60 [00:02<00:03, 11.00it/s]\u001b[A\n",
            " 45% 27/60 [00:02<00:02, 11.13it/s]\u001b[A\n",
            " 48% 29/60 [00:02<00:02, 11.14it/s]\u001b[A\n",
            " 52% 31/60 [00:02<00:02, 11.20it/s]\u001b[A\n",
            " 55% 33/60 [00:02<00:02, 11.21it/s]\u001b[A\n",
            " 58% 35/60 [00:03<00:02, 11.11it/s]\u001b[A\n",
            " 62% 37/60 [00:03<00:02, 10.86it/s]\u001b[A\n",
            " 65% 39/60 [00:03<00:01, 10.97it/s]\u001b[A\n",
            " 68% 41/60 [00:03<00:01, 11.05it/s]\u001b[A\n",
            " 72% 43/60 [00:03<00:01, 10.87it/s]\u001b[A\n",
            " 75% 45/60 [00:03<00:01, 10.98it/s]\u001b[A\n",
            " 78% 47/60 [00:04<00:01, 10.64it/s]\u001b[A\n",
            " 82% 49/60 [00:04<00:01, 10.76it/s]\u001b[A\n",
            " 85% 51/60 [00:04<00:00, 10.94it/s]\u001b[A\n",
            " 88% 53/60 [00:04<00:00, 11.00it/s]\u001b[A\n",
            " 92% 55/60 [00:04<00:00, 10.93it/s]\u001b[A\n",
            " 95% 57/60 [00:05<00:00, 10.86it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.006749338004738092, 'eval_ADDRESS_precision': 0.9047619047619048, 'eval_ADDRESS_recall': 0.95, 'eval_ADDRESS_f1': 0.9268292682926829, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.8888888888888888, 'eval_EIN_recall': 0.8888888888888888, 'eval_EIN_f1': 0.8888888888888888, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 1.0, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 1.0, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.8888888888888888, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.9142857142857143, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.7692307692307693, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.8333333333333333, 'eval_SSN_number': 11, 'eval_overall_precision': 0.928, 'eval_overall_recall': 0.9666666666666667, 'eval_overall_f1': 0.9469387755102041, 'eval_overall_accuracy': 0.999475890985325, 'eval_runtime': 6.4115, 'eval_samples_per_second': 9.358, 'eval_steps_per_second': 9.358, 'epoch': 29.0}\n",
            " 97% 3480/3600 [1:20:27<01:00,  1.99it/s]\n",
            "100% 60/60 [00:06<00:00, 10.47it/s]\u001b[A\n",
            "{'loss': 0.0144, 'grad_norm': 0.035801444202661514, 'learning_rate': 4e-05, 'epoch': 30.0}\n",
            "100% 3600/3600 [1:23:16<00:00,  1.75it/s]\n",
            "  0% 0/60 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/60 [00:00<00:03, 19.08it/s]\u001b[A\n",
            "  7% 4/60 [00:00<00:04, 13.63it/s]\u001b[A\n",
            " 10% 6/60 [00:00<00:04, 12.23it/s]\u001b[A\n",
            " 13% 8/60 [00:00<00:04, 11.91it/s]\u001b[A\n",
            " 17% 10/60 [00:00<00:04, 11.53it/s]\u001b[A\n",
            " 20% 12/60 [00:00<00:04, 11.45it/s]\u001b[A\n",
            " 23% 14/60 [00:01<00:04, 11.01it/s]\u001b[A\n",
            " 27% 16/60 [00:01<00:03, 11.09it/s]\u001b[A\n",
            " 30% 18/60 [00:01<00:03, 11.13it/s]\u001b[A\n",
            " 33% 20/60 [00:01<00:03, 11.23it/s]\u001b[A\n",
            " 37% 22/60 [00:01<00:03, 11.06it/s]\u001b[A\n",
            " 40% 24/60 [00:02<00:03, 10.84it/s]\u001b[A\n",
            " 43% 26/60 [00:02<00:03, 10.89it/s]\u001b[A\n",
            " 47% 28/60 [00:02<00:02, 11.01it/s]\u001b[A\n",
            " 50% 30/60 [00:02<00:02, 11.14it/s]\u001b[A\n",
            " 53% 32/60 [00:02<00:02, 10.97it/s]\u001b[A\n",
            " 57% 34/60 [00:03<00:02, 11.07it/s]\u001b[A\n",
            " 60% 36/60 [00:03<00:02, 10.94it/s]\u001b[A\n",
            " 63% 38/60 [00:03<00:01, 11.07it/s]\u001b[A\n",
            " 67% 40/60 [00:03<00:01, 11.12it/s]\u001b[A\n",
            " 70% 42/60 [00:03<00:01, 10.96it/s]\u001b[A\n",
            " 73% 44/60 [00:03<00:01, 11.06it/s]\u001b[A\n",
            " 77% 46/60 [00:04<00:01, 11.00it/s]\u001b[A\n",
            " 80% 48/60 [00:04<00:01, 10.73it/s]\u001b[A\n",
            " 83% 50/60 [00:04<00:00, 10.89it/s]\u001b[A\n",
            " 87% 52/60 [00:04<00:00, 10.96it/s]\u001b[A\n",
            " 90% 54/60 [00:04<00:00, 11.08it/s]\u001b[A\n",
            " 93% 56/60 [00:05<00:00, 11.07it/s]\u001b[A\n",
            " 97% 58/60 [00:05<00:00, 11.09it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.006075658369809389, 'eval_ADDRESS_precision': 1.0, 'eval_ADDRESS_recall': 1.0, 'eval_ADDRESS_f1': 1.0, 'eval_ADDRESS_number': 20, 'eval_BUSINESS_NAME_precision': 0.8, 'eval_BUSINESS_NAME_recall': 1.0, 'eval_BUSINESS_NAME_f1': 0.888888888888889, 'eval_BUSINESS_NAME_number': 4, 'eval_CITY_STATE_ZIP_CODE_precision': 1.0, 'eval_CITY_STATE_ZIP_CODE_recall': 1.0, 'eval_CITY_STATE_ZIP_CODE_f1': 1.0, 'eval_CITY_STATE_ZIP_CODE_number': 20, 'eval_EIN_precision': 0.8888888888888888, 'eval_EIN_recall': 0.8888888888888888, 'eval_EIN_f1': 0.8888888888888888, 'eval_EIN_number': 9, 'eval_LIST_ACCOUNT_NUMBER_precision': 0.95, 'eval_LIST_ACCOUNT_NUMBER_recall': 1.0, 'eval_LIST_ACCOUNT_NUMBER_f1': 0.9743589743589743, 'eval_LIST_ACCOUNT_NUMBER_number': 19, 'eval_NAME_precision': 1.0, 'eval_NAME_recall': 1.0, 'eval_NAME_f1': 1.0, 'eval_NAME_number': 20, 'eval_SIGN-DATE_precision': 0.8, 'eval_SIGN-DATE_recall': 0.9411764705882353, 'eval_SIGN-DATE_f1': 0.8648648648648648, 'eval_SIGN-DATE_number': 17, 'eval_SSN_precision': 0.7692307692307693, 'eval_SSN_recall': 0.9090909090909091, 'eval_SSN_f1': 0.8333333333333333, 'eval_SSN_number': 11, 'eval_overall_precision': 0.9212598425196851, 'eval_overall_recall': 0.975, 'eval_overall_f1': 0.9473684210526315, 'eval_overall_accuracy': 0.9993952588292211, 'eval_runtime': 6.0771, 'eval_samples_per_second': 9.873, 'eval_steps_per_second': 9.873, 'epoch': 30.0}\n",
            "100% 3600/3600 [1:23:22<00:00,  1.75it/s]\n",
            "100% 60/60 [00:05<00:00, 11.55it/s]\u001b[A\n",
            "{'train_runtime': 5106.972, 'train_samples_per_second': 1.41, 'train_steps_per_second': 0.705, 'train_loss': 0.1361143640677134, 'epoch': 30.0}\n",
            "100% 3600/3600 [1:25:01<00:00,  1.42s/it]\n",
            "100% 60/60 [00:07<00:00,  7.80it/s]\n",
            "***** Eval results *****\n",
            "epoch = 30.0\n",
            "\n",
            "eval_ADDRESS_f1 = 1.0\n",
            "\n",
            "eval_ADDRESS_number = 20\n",
            "\n",
            "eval_ADDRESS_precision = 1.0\n",
            "\n",
            "eval_ADDRESS_recall = 1.0\n",
            "\n",
            "eval_BUSINESS_NAME_f1 = 0.888888888888889\n",
            "\n",
            "eval_BUSINESS_NAME_number = 4\n",
            "\n",
            "eval_BUSINESS_NAME_precision = 0.8\n",
            "\n",
            "eval_BUSINESS_NAME_recall = 1.0\n",
            "\n",
            "eval_CITY_STATE_ZIP_CODE_f1 = 1.0\n",
            "\n",
            "eval_CITY_STATE_ZIP_CODE_number = 20\n",
            "\n",
            "eval_CITY_STATE_ZIP_CODE_precision = 1.0\n",
            "\n",
            "eval_CITY_STATE_ZIP_CODE_recall = 1.0\n",
            "\n",
            "eval_EIN_f1 = 1.0\n",
            "\n",
            "eval_EIN_number = 9\n",
            "\n",
            "eval_EIN_precision = 1.0\n",
            "\n",
            "eval_EIN_recall = 1.0\n",
            "\n",
            "eval_LIST_ACCOUNT_NUMBER_f1 = 1.0\n",
            "\n",
            "eval_LIST_ACCOUNT_NUMBER_number = 19\n",
            "\n",
            "eval_LIST_ACCOUNT_NUMBER_precision = 1.0\n",
            "\n",
            "eval_LIST_ACCOUNT_NUMBER_recall = 1.0\n",
            "\n",
            "eval_NAME_f1 = 1.0\n",
            "\n",
            "eval_NAME_number = 20\n",
            "\n",
            "eval_NAME_precision = 1.0\n",
            "\n",
            "eval_NAME_recall = 1.0\n",
            "\n",
            "eval_SIGN-DATE_f1 = 0.9696969696969697\n",
            "\n",
            "eval_SIGN-DATE_number = 17\n",
            "\n",
            "eval_SIGN-DATE_precision = 1.0\n",
            "\n",
            "eval_SIGN-DATE_recall = 0.9411764705882353\n",
            "\n",
            "eval_SSN_f1 = 0.9090909090909091\n",
            "\n",
            "eval_SSN_number = 11\n",
            "\n",
            "eval_SSN_precision = 0.9090909090909091\n",
            "\n",
            "eval_SSN_recall = 0.9090909090909091\n",
            "\n",
            "eval_loss = 0.011452929116785526\n",
            "\n",
            "eval_overall_accuracy = 0.9993549427511692\n",
            "\n",
            "eval_overall_f1 = 0.9833333333333333\n",
            "\n",
            "eval_overall_precision = 0.9833333333333333\n",
            "\n",
            "eval_overall_recall = 0.9833333333333333\n",
            "\n",
            "eval_runtime = 7.9901\n",
            "\n",
            "eval_samples_per_second = 7.509\n",
            "\n",
            "eval_steps_per_second = 7.509\n",
            "\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[1;34mwandb\u001b[0m: \u001b[1mwandb sync /content/wandb/offline-run-20250816_040330-snxzko70\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/offline-run-20250816_040330-snxzko70/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "! python3 layoutlmV2/train.py --epochs $EPOCHS \\\n",
        "                   --train_batch_size $TRAIN_BATCH_SIZE \\\n",
        "                   --eval_batch_size $VALID_BATCH_SIZE \\\n",
        "                   --learning_rate $LEARNING_RATE \\\n",
        "                   --output_dir $MODEL_OUTPUT_PATH \\\n",
        "                   --data_dir $PROCESSED_DATA_PATH \\\n",
        "                   --lr_scheduler_type $LR_SCHEDULER_TYPE \\\n",
        "                   --warmup_ratio $WARMUP_RATIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ0XdlqAKiJx",
        "outputId": "4dbd330d-3446-4b67-82ce-294e4c07509e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version in script: 4.56.0.dev0\n",
            "TrainingArguments location: transformers.training_args\n",
            "Transformers file path: /usr/local/lib/python3.11/dist-packages/transformers/__init__.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2001"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ],
      "source": [
        "import transformers\n",
        "\n",
        "\n",
        "print(\"Transformers version in script:\", transformers.__version__)\n",
        "print(\"TrainingArguments location:\", transformers.TrainingArguments.__module__)\n",
        "print(\"Transformers file path:\", transformers.__file__)\n",
        "2021\n",
        "2001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu9SvNA3Knfz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "mnY1SGjqDtAe",
        "outputId": "b161d174-8e86-4d4f-d984-338ee29eec27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version: 4.56.0.dev0\n",
            "TrainingArguments class: <class 'transformers.training_args.TrainingArguments'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TrainingArguments' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3271298598.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Transformers version:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TrainingArguments class:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainingArguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Currently imported TrainingArguments:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'TrainingArguments' is not defined"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"TrainingArguments class:\", transformers.TrainingArguments)\n",
        "print(\"Currently imported TrainingArguments:\", TrainingArguments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vp54EgYTDtLA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CK8YZK1LMQGC",
        "outputId": "38d7ec84-0ae2-4fb4-da5c-081689cfc28e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\t       drive\t   layoutlmv2-finetuned      lmv2-output\n",
            "50\t       g_output    layoutlmv2-finetuned.zip  sample_data\n",
            "annotation_lm  layoutlmV2  lmv2-dataset-output.zip   wandb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzCiO5cT3iae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flPIlE3PXKlF"
      },
      "outputs": [],
      "source": [
        "#!cp layoutlmv2-finetuned.pth /content/drive/MyDrive/Own-CDE/kls/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LjtvXQLvXOw",
        "outputId": "2c7dab58-abf1-4beb-876a-7eb13e9cfe24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/layoutlmv2-finetuned/ (stored 0%)\n",
            "updating: content/layoutlmv2-finetuned/runs/ (stored 0%)\n",
            "updating: content/layoutlmv2-finetuned/runs/Aug16_03-02-13_53e1cd3441ec/ (stored 0%)\n",
            "updating: content/layoutlmv2-finetuned/runs/Aug16_03-02-13_53e1cd3441ec/events.out.tfevents.1755315904.53e1cd3441ec.3498.1 (deflated 59%)\n",
            "updating: content/layoutlmv2-finetuned/runs/Aug16_03-02-13_53e1cd3441ec/events.out.tfevents.1755313352.53e1cd3441ec.3498.0 (deflated 76%)\n",
            "updating: content/layoutlmv2-finetuned/config.json (deflated 68%)\n",
            "updating: content/layoutlmv2-finetuned/vocab.txt (deflated 53%)\n",
            "updating: content/layoutlmv2-finetuned/tokenizer_config.json (deflated 75%)\n",
            "updating: content/layoutlmv2-finetuned/tokenizer.json (deflated 71%)\n",
            "updating: content/layoutlmv2-finetuned/model.safetensors (deflated 7%)\n",
            "updating: content/layoutlmv2-finetuned/special_tokens_map.json (deflated 80%)\n",
            "updating: content/layoutlmv2-finetuned/training_args.bin (deflated 52%)\n",
            "  adding: content/layoutlmv2-finetuned/runs/Aug16_04-03-19_53e1cd3441ec/ (stored 0%)\n",
            "  adding: content/layoutlmv2-finetuned/runs/Aug16_04-03-19_53e1cd3441ec/events.out.tfevents.1755322120.53e1cd3441ec.20020.1 (deflated 58%)\n",
            "  adding: content/layoutlmv2-finetuned/runs/Aug16_04-03-19_53e1cd3441ec/events.out.tfevents.1755317005.53e1cd3441ec.20020.0 (deflated 75%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/ (stored 0%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/rng_state.pth (deflated 25%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/optimizer.pt (deflated 19%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/config.json (deflated 68%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/vocab.txt (deflated 53%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/trainer_state.json (deflated 91%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/tokenizer_config.json (deflated 75%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/tokenizer.json (deflated 71%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/model.safetensors (deflated 7%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/special_tokens_map.json (deflated 80%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/scheduler.pt (deflated 57%)\n",
            "  adding: content/layoutlmv2-finetuned/checkpoint-2520/training_args.bin (deflated 52%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/layoutlmv2-finetuned.zip /content/layoutlmv2-finetuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO0eCwo1Twe6",
        "outputId": "9e36f362-445c-47fa-f311-956451c286d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'layoutlmv2-finetuned.zip': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp layoutlmv2-finetuned.zip /content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6feNCdnaVwl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "XH4L0YqMaV0i",
        "outputId": "b82e9b93-bee1-4ca7-9fc4-be22ca2f6851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-cloud-vision\n",
            "  Downloading google_cloud_vision-3.10.2-py3-none-any.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision) (2025.8.3)\n",
            "Downloading google_cloud_vision-3.10.2-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-vision\n",
            "Successfully installed google-cloud-vision-3.10.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "824fdd886645460f973cb20940164ed1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade google-cloud-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LXr6catTwiF"
      },
      "outputs": [],
      "source": [
        "!pip install -q nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e4Cc-GVTwly",
        "outputId": "5cf40165-f10c-4563-e053-076bd2f5ca73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package english_wordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/english_wordnet.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package mock_corpus to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmMjzmgYUNbf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import logging\n",
        "\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from numpy.random import randint\n",
        "from transformers import LayoutLMv2Processor\n",
        "\n",
        "import warnings\n",
        "import gc\n",
        "#import pytesseract\n",
        "import shutil\n",
        "import random\n",
        "import pandas as pd\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5s7RAdjUHhA"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.cloud import vision\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/content//drive/MyDrive/visual-doc-data/absolute-shell-467015-b6-3c45216adcf6.json'\n",
        "client = vision.ImageAnnotatorClient()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7OIoT-NUHxk"
      },
      "outputs": [],
      "source": [
        "#path=\"/content/prd/001.jpg\"\n",
        "\n",
        "\n",
        "def get_ocr(content):\n",
        "    #with io.open(path, 'rb') as image_file:\n",
        "        #content = image_file.read()\n",
        "\n",
        "    image = vision.Image(content=content)\n",
        "    #response = client.document_text_detection(image=image)\n",
        "    response = client.document_text_detection(image=image,image_context={\"language_hints\": [\"en\"]})\n",
        "\n",
        "    texts = response.text_annotations\n",
        "\n",
        "    text_list=[]\n",
        "    left_list=[]\n",
        "    top_list=[]\n",
        "    width_list=[]\n",
        "    height_list=[]\n",
        "    for i in range(1,len(texts)):\n",
        "        txt=texts[i].description\n",
        "        left=texts[i].bounding_poly.vertices[0].x\n",
        "        top=texts[i].bounding_poly.vertices[0].y\n",
        "        #width=texts[i].bounding_poly.vertices[1].x-texts[i].bounding_poly.vertices[0].x\n",
        "        #height=texts[i].bounding_poly.vertices[3].y-texts[i].bounding_poly.vertices[1].y\n",
        "        width=texts[i].bounding_poly.vertices[2].x-texts[i].bounding_poly.vertices[0].x\n",
        "        height=texts[i].bounding_poly.vertices[2].y-texts[i].bounding_poly.vertices[0].y\n",
        "\n",
        "        text_list.append(txt)\n",
        "        #left_list.append(abs(left))\n",
        "        #top_list.append(abs(top))\n",
        "        #width_list.append(abs(width))\n",
        "        #height_list.append(abs(height))\n",
        "\n",
        "        left_list.append(left)\n",
        "        top_list.append(top)\n",
        "        #width_list.append(texts[i].bounding_poly.vertices[2].x)\n",
        "        #height_list.append(texts[i].bounding_poly.vertices[2].y)\n",
        "        width_list.append(width)\n",
        "        height_list.append(height)\n",
        "\n",
        "\n",
        "    print(len(text_list),len(left_list),len(top_list),len(width_list),len(height_list))\n",
        "\n",
        "    #create new df\n",
        "    df = pd.DataFrame({'left':left_list,'top':top_list,'width':width_list,'height':height_list,'text':text_list})\n",
        "    print(df.shape)\n",
        "\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJA7uf17asQE"
      },
      "outputs": [],
      "source": [
        "#Helper functions\n",
        "def random_color():\n",
        "  return np.random.randint(0,255,3)\n",
        "def normalize_box(bbox,width,height):\n",
        "  return [\n",
        "          int(bbox[0]*(1000/width)),\n",
        "          int(bbox[1]*(1000/height)),\n",
        "          int(bbox[2]*(1000/width)),\n",
        "          int(bbox[3]*(1000/height)),\n",
        "  ]\n",
        "\n",
        "def unnormalize_box(bbox, width, height):\n",
        "     return [\n",
        "         width * (bbox[0] / 1000),\n",
        "         height * (bbox[1] / 1000),\n",
        "         width * (bbox[2] / 1000),\n",
        "         height * (bbox[3] / 1000),\n",
        "     ]\n",
        "\n",
        "def compare_boxes(b1,b2):\n",
        "  b1 = np.array([c for c in b1])\n",
        "  b2 = np.array([c for c in b2])\n",
        "  equal = np.array_equal(b1,b2)\n",
        "  return equal\n",
        "\n",
        "def mergable(w1,w2):\n",
        "  if w1['label'] == w2['label']:\n",
        "    threshold = 7\n",
        "    if abs(w1['box'][1] - w2['box'][1]) < threshold or abs(w1['box'][-1] - w2['box'][-1]) < threshold:\n",
        "      return True\n",
        "    return False\n",
        "  return False\n",
        "\n",
        "def convert_BIOES_BIO(true_prd):\n",
        "  tags=[]\n",
        "  for i in range(len(true_prd)):\n",
        "    lbs=true_prd[i].split(\"-\")\n",
        "    if \"E\" in lbs:\n",
        "      tags.append(\"I-\"+lbs[1])\n",
        "    elif \"S\" in lbs:\n",
        "      tags.append(\"B-\"+lbs[1])\n",
        "    elif 'O' in lbs:\n",
        "      tags.append(lbs[0])\n",
        "    else:\n",
        "        tags.append(lbs[0]+\"-\"+lbs[1])\n",
        "  return tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q80-DbswUH1Y",
        "outputId": "223f1fe4-4a3b-4489-dc76-9d1f9ab38832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'O', 1: 'E-BUSINESS_NAME', 2: 'B-LIST_ACCOUNT_NUMBER', 3: 'S-NAME', 4: 'I-NAME', 5: 'E-CITY_STATE_ZIP_CODE', 6: 'B-SSN', 7: 'S-EIN', 8: 'B-NAME', 9: 'B-EIN', 10: 'E-SSN', 11: 'B-BUSINESS_NAME', 12: 'I-BUSINESS_NAME', 13: 'I-SIGN-DATE', 14: 'E-LIST_ACCOUNT_NUMBER', 15: 'E-NAME', 16: 'S-LIST_ACCOUNT_NUMBER', 17: 'I-SSN', 18: 'E-ADDRESS', 19: 'I-ADDRESS', 20: 'S-SIGN-DATE', 21: 'B-SIGN-DATE', 22: 'B-CITY_STATE_ZIP_CODE', 23: 'E-SIGN-DATE', 24: 'I-CITY_STATE_ZIP_CODE', 25: 'B-ADDRESS', 26: 'S-SSN', 27: 'E-EIN', 28: 'I-LIST_ACCOUNT_NUMBER'}\n",
            "--- 8.064785242080688 seconds ---\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "#from pytesseract import Output\n",
        "from transformers import LayoutLMv2Processor\n",
        "from transformers import LayoutLMv2ForTokenClassification\n",
        "\n",
        "start_time = time.time()\n",
        "#load processor for encoding\n",
        "processor = LayoutLMv2Processor.from_pretrained(\"microsoft/layoutlmv2-base-uncased\", revision=\"no_ocr\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# load the fine-tuned model from the hub\n",
        "pan_model = LayoutLMv2ForTokenClassification.from_pretrained(\"/content/layoutlmv2-finetuned\")\n",
        "pan_id2label = pan_model.config.id2label\n",
        "print(pan_id2label)\n",
        "#pan_model.to(device\n",
        "pan_model.to(device)\n",
        "\n",
        "#model = LayoutLMv2ForTokenClassification.from_pretrained(\"/content/layoutlmv2-finetuned\")\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83df89gTdx9m"
      },
      "outputs": [],
      "source": [
        "def get_pan_model_go(img_data,ocr_type,outfilename):\n",
        "  start_time1 = time.time()\n",
        "  #output_path = \"/content/Inference_output1\"\n",
        "  #os.makedirs(output_path,exist_ok=True)\n",
        "  no_ocr=[]\n",
        "\n",
        "  start_time2 = time.time()\n",
        "  #print(imag_path)\n",
        "  start_time = time.time()\n",
        "  img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "  #Image OCR by using pytesseract\n",
        "  #img=Image.open(imag_path)\n",
        "  if ocr_type=='Model-GO':\n",
        "    print(\"Google OCR Used \")\n",
        "    ocr_df=get_ocr(img_data)\n",
        "  else:\n",
        "    print(\"Pytesseract OCR Used \")\n",
        "    #img = Image.open(io.BytesIO(img))\n",
        "    ocr_df=pytesseract.image_to_data(img, output_type=Output.DATAFRAME)\n",
        "\n",
        "  print(\"OCR --- %s seconds ---\" % (time.time() - start_time))\n",
        "  print(\"Dataframe Shape:  \",ocr_df.shape)\n",
        "  ocr_df = ocr_df.dropna()\n",
        "  print(\"Dataframe Shape After remove NA:  \",ocr_df.shape)\n",
        "\n",
        "  ocr_df = ocr_df[ocr_df.select_dtypes(include=[np.number]).ge(0).all(1)]\n",
        "  print(\"Dataframe Shape After remove Negative:  \",ocr_df.shape)\n",
        "\n",
        "  #ocr_df.drop(ocr_df.index[-1], inplace=True)\n",
        "  #print(\"Dataframe Shape After remove Last row:  \",ocr_df.shape)\n",
        "\n",
        "  outfile_ocr=output_dir+outfilename+\"_ocr.csv\"\n",
        "  print(outfile_ocr)\n",
        "  ocr_df.to_csv(outfile_ocr,index=False,encoding='utf-8')\n",
        "\n",
        "  if ocr_df.shape[0]>0:\n",
        "    text_output = ocr_df.text.tolist()\n",
        "    doc_text = ' '.join(text_output)\n",
        "\n",
        "    #read an image file for inference\n",
        "    #inference_image = Image.open(imag_path).convert('RGB')\n",
        "    #img = Image.open(io.BytesIO(img))\n",
        "    inference_image = img.convert('RGB')\n",
        "    width, height = inference_image.size\n",
        "    print(width, height)\n",
        "\n",
        "    #extract all the token and bbox and normalized the bbox\n",
        "    words = []\n",
        "    for index,row in ocr_df.iterrows():\n",
        "      word = {}\n",
        "      origin_box = [row['left'],row['top'],row['left']+row['width'],row['top']+row['height']]\n",
        "      #origin_box = [row['left'],row['top'],row['width'],row['height']]\n",
        "      word['word_text'] = row['text']\n",
        "      word['word_box'] = origin_box\n",
        "      word['normalized_box'] = normalize_box(word['word_box'],width, height)\n",
        "      words.append(word)\n",
        "\n",
        "    boxlist = [word['normalized_box'] for word in words]\n",
        "    wordlist = [word['word_text'] for word in words]\n",
        "    #print(wordlist)\n",
        "    print(\"Total words and bboxs: \", len(boxlist),len(wordlist))\n",
        "\n",
        "    #encode input data(ocr words and bboxs)\n",
        "    encoded_inputs = processor(inference_image,wordlist,boxes=boxlist, return_offsets_mapping=True, return_tensors=\"pt\",max_length=512,truncation=True)\n",
        "    offset_mapping = encoded_inputs.pop('offset_mapping')\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    for k,v in encoded_inputs.items():\n",
        "      encoded_inputs[k] = v.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = pan_model(**encoded_inputs)\n",
        "    print(outputs.logits.shape)\n",
        "\n",
        "    predictions = outputs.logits.argmax(-1).squeeze().tolist()\n",
        "    token_boxes = encoded_inputs.bbox.squeeze().tolist()\n",
        "\n",
        "    is_subword = np.array(offset_mapping.squeeze().tolist())[:,0] != 0\n",
        "\n",
        "    true_predictions = [pan_id2label[pred] for idx, pred in enumerate(predictions) if not is_subword[idx]]\n",
        "    true_boxes = [unnormalize_box(box, width, height) for idx, box in enumerate(token_boxes) if not is_subword[idx]]\n",
        "\n",
        "    true_predictions=true_predictions[1:-1]\n",
        "\n",
        "    tags = convert_BIOES_BIO(true_predictions)\n",
        "    tokens = wordlist\n",
        "\n",
        "\n",
        "    # tag each token with pos\n",
        "    pos_tags = [pos for token, pos in pos_tag(tokens)]\n",
        "    # convert the BIO / IOB tags to tree\n",
        "    conlltags = [(token, pos, tg) for token, pos, tg in zip(tokens, pos_tags, tags)]\n",
        "    ne_tree = conlltags2tree(conlltags)\n",
        "    # parse the tree to get our original text\n",
        "    original_text = []\n",
        "    for subtree in ne_tree:\n",
        "        # checking for 'O' tags\n",
        "        if type(subtree) == Tree:\n",
        "            original_label = subtree.label()\n",
        "            original_string = \" \".join([token for token, pos in subtree.leaves()])\n",
        "            original_text.append((original_string, original_label))\n",
        "    print(original_text)\n",
        "\n",
        "  else:\n",
        "    #print(\"OCR Not Detected: \",imag_path)\n",
        "    print(\"OCR Not Detected\")\n",
        "    #no_ocr.append(imag_path)\n",
        "    filtered_words_f=[]\n",
        "    original_text = []\n",
        "  print(\"File processed --- %s seconds ---\" % (time.time() - start_time2))\n",
        "\n",
        "  return original_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb8YFoLhdyAr",
        "outputId": "26dc8c23-909a-4342-d450-fceeccd4403c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "input_dir_name='/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/'\n",
        "file_list=[]\n",
        "for file in os.listdir(input_dir_name):\n",
        "    file_list.append(file)\n",
        "print(len(file_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqt10VmedyDp",
        "outputId": "22ba509f-e2a7-4e34-adda-3bf9fa58d3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_004.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.6721749305725098 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_004_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 5.251585483551025 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_008.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.6284990310668945 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_008_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.9466094970703125 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_005.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.6427497863769531 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_005_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.9621436595916748 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_037.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.7161481380462646 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_037_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.0279316902160645 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_032.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.5489881038665771 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_032_ocr.csv\n",
            "1735 2304\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.8474774360656738 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_013.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.8989410400390625 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_013_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.366786479949951 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_035.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.356306552886963 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_035_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7189836502075195 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_012.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1153 1153 1153 1153 1153\n",
            "(1153, 5)\n",
            "OCR --- 1.2860980033874512 seconds ---\n",
            "Dataframe Shape:   (1153, 5)\n",
            "Dataframe Shape After remove NA:   (1153, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_012_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5838658809661865 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_019.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1153 1153 1153 1153 1153\n",
            "(1153, 5)\n",
            "OCR --- 1.2340359687805176 seconds ---\n",
            "Dataframe Shape:   (1153, 5)\n",
            "Dataframe Shape After remove NA:   (1153, 5)\n",
            "Dataframe Shape After remove Negative:   (1142, 5)\n",
            "/content/g_output/w9_forms_019_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1142 1142\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5001301765441895 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_025.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1145 1145 1145 1145 1145\n",
            "(1145, 5)\n",
            "OCR --- 1.244102954864502 seconds ---\n",
            "Dataframe Shape:   (1145, 5)\n",
            "Dataframe Shape After remove NA:   (1145, 5)\n",
            "Dataframe Shape After remove Negative:   (1134, 5)\n",
            "/content/g_output/w9_forms_025_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1134 1134\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.526427984237671 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_021.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.3377115726470947 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_021_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.613839864730835 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_018.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1144 1144 1144 1144 1144\n",
            "(1144, 5)\n",
            "OCR --- 1.2292909622192383 seconds ---\n",
            "Dataframe Shape:   (1144, 5)\n",
            "Dataframe Shape After remove NA:   (1144, 5)\n",
            "Dataframe Shape After remove Negative:   (1133, 5)\n",
            "/content/g_output/w9_forms_018_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1133 1133\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4973268508911133 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_030.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1159 1159 1159 1159 1159\n",
            "(1159, 5)\n",
            "OCR --- 1.3389289379119873 seconds ---\n",
            "Dataframe Shape:   (1159, 5)\n",
            "Dataframe Shape After remove NA:   (1159, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_030_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6240208148956299 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_022.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1163 1163 1163 1163 1163\n",
            "(1163, 5)\n",
            "OCR --- 1.4132769107818604 seconds ---\n",
            "Dataframe Shape:   (1163, 5)\n",
            "Dataframe Shape After remove NA:   (1163, 5)\n",
            "Dataframe Shape After remove Negative:   (1152, 5)\n",
            "/content/g_output/w9_forms_022_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1152 1152\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6928329467773438 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_051.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.7312290668487549 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_051_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.2775826454162598 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_063.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1150 1150 1150 1150 1150\n",
            "(1150, 5)\n",
            "OCR --- 1.4388418197631836 seconds ---\n",
            "Dataframe Shape:   (1150, 5)\n",
            "Dataframe Shape After remove NA:   (1150, 5)\n",
            "Dataframe Shape After remove Negative:   (1139, 5)\n",
            "/content/g_output/w9_forms_063_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1139 1139\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7967703342437744 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_057.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1149 1149 1149 1149 1149\n",
            "(1149, 5)\n",
            "OCR --- 1.740297794342041 seconds ---\n",
            "Dataframe Shape:   (1149, 5)\n",
            "Dataframe Shape After remove NA:   (1149, 5)\n",
            "Dataframe Shape After remove Negative:   (1138, 5)\n",
            "/content/g_output/w9_forms_057_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1138 1138\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.015798330307007 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_039.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1153 1153 1153 1153 1153\n",
            "(1153, 5)\n",
            "OCR --- 1.2151613235473633 seconds ---\n",
            "Dataframe Shape:   (1153, 5)\n",
            "Dataframe Shape After remove NA:   (1153, 5)\n",
            "Dataframe Shape After remove Negative:   (1142, 5)\n",
            "/content/g_output/w9_forms_039_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1142 1142\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4747710227966309 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_058.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.2237823009490967 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_058_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.479184865951538 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_045.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1150 1150 1150 1150 1150\n",
            "(1150, 5)\n",
            "OCR --- 1.3629209995269775 seconds ---\n",
            "Dataframe Shape:   (1150, 5)\n",
            "Dataframe Shape After remove NA:   (1150, 5)\n",
            "Dataframe Shape After remove Negative:   (1139, 5)\n",
            "/content/g_output/w9_forms_045_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1139 1139\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6236588954925537 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_062.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.6787123680114746 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_062_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.9926087856292725 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_050.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1155 1155 1155 1155 1155\n",
            "(1155, 5)\n",
            "OCR --- 1.3820314407348633 seconds ---\n",
            "Dataframe Shape:   (1155, 5)\n",
            "Dataframe Shape After remove NA:   (1155, 5)\n",
            "Dataframe Shape After remove Negative:   (1144, 5)\n",
            "/content/g_output/w9_forms_050_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1144 1144\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7429513931274414 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_038.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.2043964862823486 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_038_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4667158126831055 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_052.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1150 1150 1150 1150 1150\n",
            "(1150, 5)\n",
            "OCR --- 1.6191463470458984 seconds ---\n",
            "Dataframe Shape:   (1150, 5)\n",
            "Dataframe Shape After remove NA:   (1150, 5)\n",
            "Dataframe Shape After remove Negative:   (1139, 5)\n",
            "/content/g_output/w9_forms_052_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1139 1139\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.8776140213012695 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_059.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.3425624370574951 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_059_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7214221954345703 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_093.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.2959933280944824 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_093_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5565671920776367 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_097.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.5961229801177979 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_097_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.8491711616516113 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_069.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1151 1151 1151 1151 1151\n",
            "(1151, 5)\n",
            "OCR --- 1.2050914764404297 seconds ---\n",
            "Dataframe Shape:   (1151, 5)\n",
            "Dataframe Shape After remove NA:   (1151, 5)\n",
            "Dataframe Shape After remove Negative:   (1140, 5)\n",
            "/content/g_output/w9_forms_069_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1140 1140\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4570801258087158 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_076.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1159 1159 1159 1159 1159\n",
            "(1159, 5)\n",
            "OCR --- 1.3657925128936768 seconds ---\n",
            "Dataframe Shape:   (1159, 5)\n",
            "Dataframe Shape After remove NA:   (1159, 5)\n",
            "Dataframe Shape After remove Negative:   (1148, 5)\n",
            "/content/g_output/w9_forms_076_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1148 1148\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.74826979637146 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_074.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.6274781227111816 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_074_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.0329737663269043 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_070.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1151 1151 1151 1151 1151\n",
            "(1151, 5)\n",
            "OCR --- 1.3983979225158691 seconds ---\n",
            "Dataframe Shape:   (1151, 5)\n",
            "Dataframe Shape After remove NA:   (1151, 5)\n",
            "Dataframe Shape After remove Negative:   (1140, 5)\n",
            "/content/g_output/w9_forms_070_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1140 1140\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6455962657928467 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_078.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1150 1150 1150 1150 1150\n",
            "(1150, 5)\n",
            "OCR --- 1.2695140838623047 seconds ---\n",
            "Dataframe Shape:   (1150, 5)\n",
            "Dataframe Shape After remove NA:   (1150, 5)\n",
            "Dataframe Shape After remove Negative:   (1139, 5)\n",
            "/content/g_output/w9_forms_078_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1139 1139\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5325253009796143 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_095.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.394141435623169 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_095_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6648075580596924 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_082.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1151 1151 1151 1151 1151\n",
            "(1151, 5)\n",
            "OCR --- 1.3324322700500488 seconds ---\n",
            "Dataframe Shape:   (1151, 5)\n",
            "Dataframe Shape After remove NA:   (1151, 5)\n",
            "Dataframe Shape After remove Negative:   (1140, 5)\n",
            "/content/g_output/w9_forms_082_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1140 1140\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.702730417251587 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_072.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.696977138519287 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_072_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.1440062522888184 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_084.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1151 1151 1151 1151 1151\n",
            "(1151, 5)\n",
            "OCR --- 1.3891162872314453 seconds ---\n",
            "Dataframe Shape:   (1151, 5)\n",
            "Dataframe Shape After remove NA:   (1151, 5)\n",
            "Dataframe Shape After remove Negative:   (1140, 5)\n",
            "/content/g_output/w9_forms_084_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1140 1140\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7563092708587646 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_089.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.3734686374664307 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_089_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7637648582458496 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_105.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1144 1144 1144 1144 1144\n",
            "(1144, 5)\n",
            "OCR --- 1.183934211730957 seconds ---\n",
            "Dataframe Shape:   (1144, 5)\n",
            "Dataframe Shape After remove NA:   (1144, 5)\n",
            "Dataframe Shape After remove Negative:   (1133, 5)\n",
            "/content/g_output/w9_forms_105_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1133 1133\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4484758377075195 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_104.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1146 1146 1146 1146 1146\n",
            "(1146, 5)\n",
            "OCR --- 1.7089147567749023 seconds ---\n",
            "Dataframe Shape:   (1146, 5)\n",
            "Dataframe Shape After remove NA:   (1146, 5)\n",
            "Dataframe Shape After remove Negative:   (1137, 5)\n",
            "/content/g_output/w9_forms_104_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1137 1137\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.0403757095336914 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_122.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.628014087677002 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_122_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.9343633651733398 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_114.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.188364028930664 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_114_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4485678672790527 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_118.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.653357744216919 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_118_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.9622478485107422 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_099.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.3809669017791748 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_099_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7739789485931396 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_120.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1151 1151 1151 1151 1151\n",
            "(1151, 5)\n",
            "OCR --- 1.3321058750152588 seconds ---\n",
            "Dataframe Shape:   (1151, 5)\n",
            "Dataframe Shape After remove NA:   (1151, 5)\n",
            "Dataframe Shape After remove Negative:   (1140, 5)\n",
            "/content/g_output/w9_forms_120_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1140 1140\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.761317491531372 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_119.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1148 1148 1148 1148 1148\n",
            "(1148, 5)\n",
            "OCR --- 1.2853894233703613 seconds ---\n",
            "Dataframe Shape:   (1148, 5)\n",
            "Dataframe Shape After remove NA:   (1148, 5)\n",
            "Dataframe Shape After remove Negative:   (1137, 5)\n",
            "/content/g_output/w9_forms_119_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1137 1137\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6707568168640137 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_121.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.7901403903961182 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_121_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.451014995574951 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_109.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.2099487781524658 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1144, 5)\n",
            "/content/g_output/w9_forms_109_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1144 1144\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4661645889282227 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_100.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1146 1146 1146 1146 1146\n",
            "(1146, 5)\n",
            "OCR --- 1.357529878616333 seconds ---\n",
            "Dataframe Shape:   (1146, 5)\n",
            "Dataframe Shape After remove NA:   (1146, 5)\n",
            "Dataframe Shape After remove Negative:   (1134, 5)\n",
            "/content/g_output/w9_forms_100_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1134 1134\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6423170566558838 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_124.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1141 1141 1141 1141 1141\n",
            "(1141, 5)\n",
            "OCR --- 1.2481982707977295 seconds ---\n",
            "Dataframe Shape:   (1141, 5)\n",
            "Dataframe Shape After remove NA:   (1141, 5)\n",
            "Dataframe Shape After remove Negative:   (1130, 5)\n",
            "/content/g_output/w9_forms_124_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1130 1130\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4928104877471924 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_148.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.483499526977539 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_148_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7694461345672607 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_130.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1160 1160 1160 1160 1160\n",
            "(1160, 5)\n",
            "OCR --- 1.6002182960510254 seconds ---\n",
            "Dataframe Shape:   (1160, 5)\n",
            "Dataframe Shape After remove NA:   (1160, 5)\n",
            "Dataframe Shape After remove Negative:   (1149, 5)\n",
            "/content/g_output/w9_forms_130_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1149 1149\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.999680519104004 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_150.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.7292571067810059 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_150_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.1227622032165527 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_155.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1148 1148 1148 1148 1148\n",
            "(1148, 5)\n",
            "OCR --- 1.424588680267334 seconds ---\n",
            "Dataframe Shape:   (1148, 5)\n",
            "Dataframe Shape After remove NA:   (1148, 5)\n",
            "Dataframe Shape After remove Negative:   (1134, 5)\n",
            "/content/g_output/w9_forms_155_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1134 1134\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.810547113418579 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_135.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1155 1155 1155 1155 1155\n",
            "(1155, 5)\n",
            "OCR --- 1.7052764892578125 seconds ---\n",
            "Dataframe Shape:   (1155, 5)\n",
            "Dataframe Shape After remove NA:   (1155, 5)\n",
            "Dataframe Shape After remove Negative:   (1144, 5)\n",
            "/content/g_output/w9_forms_135_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1144 1144\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.9734382629394531 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_126.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1155 1155 1155 1155 1155\n",
            "(1155, 5)\n",
            "OCR --- 1.672116756439209 seconds ---\n",
            "Dataframe Shape:   (1155, 5)\n",
            "Dataframe Shape After remove NA:   (1155, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_126_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.9408979415893555 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_125.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1151 1151 1151 1151 1151\n",
            "(1151, 5)\n",
            "OCR --- 1.2328829765319824 seconds ---\n",
            "Dataframe Shape:   (1151, 5)\n",
            "Dataframe Shape After remove NA:   (1151, 5)\n",
            "Dataframe Shape After remove Negative:   (1140, 5)\n",
            "/content/g_output/w9_forms_125_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1140 1140\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4917898178100586 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_131.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 2.05477237701416 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_131_ocr.csv\n",
            "1735 2304\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 3.6050360202789307 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_142.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1153 1153 1153 1153 1153\n",
            "(1153, 5)\n",
            "OCR --- 2.3208043575286865 seconds ---\n",
            "Dataframe Shape:   (1153, 5)\n",
            "Dataframe Shape After remove NA:   (1153, 5)\n",
            "Dataframe Shape After remove Negative:   (1142, 5)\n",
            "/content/g_output/w9_forms_142_ocr.csv\n",
            "1747 2289\n",
            "Total words and bboxs:  1142 1142\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 3.5089240074157715 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_156.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1153 1153 1153 1153 1153\n",
            "(1153, 5)\n",
            "OCR --- 2.741386890411377 seconds ---\n",
            "Dataframe Shape:   (1153, 5)\n",
            "Dataframe Shape After remove NA:   (1153, 5)\n",
            "Dataframe Shape After remove Negative:   (1142, 5)\n",
            "/content/g_output/w9_forms_156_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1142 1142\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 4.78199577331543 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_138.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1163 1163 1163 1163 1163\n",
            "(1163, 5)\n",
            "OCR --- 1.351250171661377 seconds ---\n",
            "Dataframe Shape:   (1163, 5)\n",
            "Dataframe Shape After remove NA:   (1163, 5)\n",
            "Dataframe Shape After remove Negative:   (1152, 5)\n",
            "/content/g_output/w9_forms_138_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1152 1152\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6413486003875732 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_180.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.3911519050598145 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_180_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6864867210388184 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_175.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1150 1150 1150 1150 1150\n",
            "(1150, 5)\n",
            "OCR --- 1.3798213005065918 seconds ---\n",
            "Dataframe Shape:   (1150, 5)\n",
            "Dataframe Shape After remove NA:   (1150, 5)\n",
            "Dataframe Shape After remove Negative:   (1139, 5)\n",
            "/content/g_output/w9_forms_175_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1139 1139\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7535076141357422 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_169.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.4922659397125244 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_169_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7540593147277832 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_190.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1155 1155 1155 1155 1155\n",
            "(1155, 5)\n",
            "OCR --- 1.5255846977233887 seconds ---\n",
            "Dataframe Shape:   (1155, 5)\n",
            "Dataframe Shape After remove NA:   (1155, 5)\n",
            "Dataframe Shape After remove Negative:   (1144, 5)\n",
            "/content/g_output/w9_forms_190_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1144 1144\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.797891616821289 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_170.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1149 1149 1149 1149 1149\n",
            "(1149, 5)\n",
            "OCR --- 1.2645399570465088 seconds ---\n",
            "Dataframe Shape:   (1149, 5)\n",
            "Dataframe Shape After remove NA:   (1149, 5)\n",
            "Dataframe Shape After remove Negative:   (1138, 5)\n",
            "/content/g_output/w9_forms_170_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1138 1138\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5358984470367432 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_163.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.594466209411621 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_163_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.940523386001587 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_184.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1155 1155 1155 1155 1155\n",
            "(1155, 5)\n",
            "OCR --- 1.6062650680541992 seconds ---\n",
            "Dataframe Shape:   (1155, 5)\n",
            "Dataframe Shape After remove NA:   (1155, 5)\n",
            "Dataframe Shape After remove Negative:   (1144, 5)\n",
            "/content/g_output/w9_forms_184_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1144 1144\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.0270562171936035 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_168.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1147 1147 1147 1147 1147\n",
            "(1147, 5)\n",
            "OCR --- 1.1994004249572754 seconds ---\n",
            "Dataframe Shape:   (1147, 5)\n",
            "Dataframe Shape After remove NA:   (1147, 5)\n",
            "Dataframe Shape After remove Negative:   (1136, 5)\n",
            "/content/g_output/w9_forms_168_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1136 1136\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4506299495697021 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_186.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.718031644821167 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_186_ocr.csv\n",
            "1736 2303\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.092407464981079 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_157.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1148 1148 1148 1148 1148\n",
            "(1148, 5)\n",
            "OCR --- 1.3185861110687256 seconds ---\n",
            "Dataframe Shape:   (1148, 5)\n",
            "Dataframe Shape After remove NA:   (1148, 5)\n",
            "Dataframe Shape After remove Negative:   (1136, 5)\n",
            "/content/g_output/w9_forms_157_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1136 1136\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5786468982696533 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_176.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.5814769268035889 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_176_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.8907277584075928 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_194.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.582801103591919 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_194_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.8479673862457275 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_214.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1146 1146 1146 1146 1146\n",
            "(1146, 5)\n",
            "OCR --- 1.3744988441467285 seconds ---\n",
            "Dataframe Shape:   (1146, 5)\n",
            "Dataframe Shape After remove NA:   (1146, 5)\n",
            "Dataframe Shape After remove Negative:   (1135, 5)\n",
            "/content/g_output/w9_forms_214_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1135 1135\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6402084827423096 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_208.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1148 1148 1148 1148 1148\n",
            "(1148, 5)\n",
            "OCR --- 1.1870474815368652 seconds ---\n",
            "Dataframe Shape:   (1148, 5)\n",
            "Dataframe Shape After remove NA:   (1148, 5)\n",
            "Dataframe Shape After remove Negative:   (1137, 5)\n",
            "/content/g_output/w9_forms_208_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1137 1137\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4399731159210205 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_198.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1166 1166 1166 1166 1166\n",
            "(1166, 5)\n",
            "OCR --- 1.5552170276641846 seconds ---\n",
            "Dataframe Shape:   (1166, 5)\n",
            "Dataframe Shape After remove NA:   (1166, 5)\n",
            "Dataframe Shape After remove Negative:   (1155, 5)\n",
            "/content/g_output/w9_forms_198_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1155 1155\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.8188350200653076 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_202.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1144 1144 1144 1144 1144\n",
            "(1144, 5)\n",
            "OCR --- 1.3588953018188477 seconds ---\n",
            "Dataframe Shape:   (1144, 5)\n",
            "Dataframe Shape After remove NA:   (1144, 5)\n",
            "Dataframe Shape After remove Negative:   (1133, 5)\n",
            "/content/g_output/w9_forms_202_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1133 1133\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7516279220581055 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_211.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1160 1160 1160 1160 1160\n",
            "(1160, 5)\n",
            "OCR --- 1.4100456237792969 seconds ---\n",
            "Dataframe Shape:   (1160, 5)\n",
            "Dataframe Shape After remove NA:   (1160, 5)\n",
            "Dataframe Shape After remove Negative:   (1149, 5)\n",
            "/content/g_output/w9_forms_211_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1149 1149\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.8695054054260254 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_210.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1148 1148 1148 1148 1148\n",
            "(1148, 5)\n",
            "OCR --- 1.300705909729004 seconds ---\n",
            "Dataframe Shape:   (1148, 5)\n",
            "Dataframe Shape After remove NA:   (1148, 5)\n",
            "Dataframe Shape After remove Negative:   (1135, 5)\n",
            "/content/g_output/w9_forms_210_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1135 1135\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5516550540924072 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_205.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1143 1143 1143 1143 1143\n",
            "(1143, 5)\n",
            "OCR --- 1.3369834423065186 seconds ---\n",
            "Dataframe Shape:   (1143, 5)\n",
            "Dataframe Shape After remove NA:   (1143, 5)\n",
            "Dataframe Shape After remove Negative:   (1131, 5)\n",
            "/content/g_output/w9_forms_205_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1131 1131\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5830912590026855 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_216.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1147 1147 1147 1147 1147\n",
            "(1147, 5)\n",
            "OCR --- 1.2155845165252686 seconds ---\n",
            "Dataframe Shape:   (1147, 5)\n",
            "Dataframe Shape After remove NA:   (1147, 5)\n",
            "Dataframe Shape After remove Negative:   (1135, 5)\n",
            "/content/g_output/w9_forms_216_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1135 1135\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.473529577255249 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_206.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.3366672992706299 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_206_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6086435317993164 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_203.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1142 1142 1142 1142 1142\n",
            "(1142, 5)\n",
            "OCR --- 1.1354007720947266 seconds ---\n",
            "Dataframe Shape:   (1142, 5)\n",
            "Dataframe Shape After remove NA:   (1142, 5)\n",
            "Dataframe Shape After remove Negative:   (1131, 5)\n",
            "/content/g_output/w9_forms_203_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1131 1131\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.392690896987915 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_229.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1160 1160 1160 1160 1160\n",
            "(1160, 5)\n",
            "OCR --- 1.2736620903015137 seconds ---\n",
            "Dataframe Shape:   (1160, 5)\n",
            "Dataframe Shape After remove NA:   (1160, 5)\n",
            "Dataframe Shape After remove Negative:   (1149, 5)\n",
            "/content/g_output/w9_forms_229_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1149 1149\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.540771722793579 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_227.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1159 1159 1159 1159 1159\n",
            "(1159, 5)\n",
            "OCR --- 1.4075744152069092 seconds ---\n",
            "Dataframe Shape:   (1159, 5)\n",
            "Dataframe Shape After remove NA:   (1159, 5)\n",
            "Dataframe Shape After remove Negative:   (1148, 5)\n",
            "/content/g_output/w9_forms_227_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1148 1148\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7755610942840576 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_217.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1155 1155 1155 1155 1155\n",
            "(1155, 5)\n",
            "OCR --- 1.2607159614562988 seconds ---\n",
            "Dataframe Shape:   (1155, 5)\n",
            "Dataframe Shape After remove NA:   (1155, 5)\n",
            "Dataframe Shape After remove Negative:   (1144, 5)\n",
            "/content/g_output/w9_forms_217_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1144 1144\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6664602756500244 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_231.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.3178555965423584 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_231_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6751494407653809 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_221.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.5249855518341064 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_221_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.8035228252410889 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_236.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.5811140537261963 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_236_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.892972469329834 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_225.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1153 1153 1153 1153 1153\n",
            "(1153, 5)\n",
            "OCR --- 1.1704046726226807 seconds ---\n",
            "Dataframe Shape:   (1153, 5)\n",
            "Dataframe Shape After remove NA:   (1153, 5)\n",
            "Dataframe Shape After remove Negative:   (1142, 5)\n",
            "/content/g_output/w9_forms_225_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1142 1142\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4406328201293945 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_239.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.3567895889282227 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_239_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6072206497192383 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_219.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.705883264541626 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_219_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.1616997718811035 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_241.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1150 1150 1150 1150 1150\n",
            "(1150, 5)\n",
            "OCR --- 1.3321573734283447 seconds ---\n",
            "Dataframe Shape:   (1150, 5)\n",
            "Dataframe Shape After remove NA:   (1150, 5)\n",
            "Dataframe Shape After remove Negative:   (1139, 5)\n",
            "/content/g_output/w9_forms_241_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1139 1139\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7118110656738281 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_224.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.479283094406128 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_224_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7731397151947021 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_267.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1150 1150 1150 1150 1150\n",
            "(1150, 5)\n",
            "OCR --- 1.198136568069458 seconds ---\n",
            "Dataframe Shape:   (1150, 5)\n",
            "Dataframe Shape After remove NA:   (1150, 5)\n",
            "Dataframe Shape After remove Negative:   (1139, 5)\n",
            "/content/g_output/w9_forms_267_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1139 1139\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4688408374786377 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_265.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1151 1151 1151 1151 1151\n",
            "(1151, 5)\n",
            "OCR --- 1.2313323020935059 seconds ---\n",
            "Dataframe Shape:   (1151, 5)\n",
            "Dataframe Shape After remove NA:   (1151, 5)\n",
            "Dataframe Shape After remove Negative:   (1140, 5)\n",
            "/content/g_output/w9_forms_265_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1140 1140\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6104893684387207 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_252.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.3048827648162842 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_252_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.683739423751831 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_248.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.7150952816009521 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_248_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 2.0456151962280273 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_249.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1164 1164 1164 1164 1164\n",
            "(1164, 5)\n",
            "OCR --- 1.3027312755584717 seconds ---\n",
            "Dataframe Shape:   (1164, 5)\n",
            "Dataframe Shape After remove NA:   (1164, 5)\n",
            "Dataframe Shape After remove Negative:   (1152, 5)\n",
            "/content/g_output/w9_forms_249_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1152 1152\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5599172115325928 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_263.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1147 1147 1147 1147 1147\n",
            "(1147, 5)\n",
            "OCR --- 1.3889086246490479 seconds ---\n",
            "Dataframe Shape:   (1147, 5)\n",
            "Dataframe Shape After remove NA:   (1147, 5)\n",
            "Dataframe Shape After remove Negative:   (1136, 5)\n",
            "/content/g_output/w9_forms_263_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1136 1136\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7399108409881592 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_250.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.2432491779327393 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_250_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5336179733276367 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_261.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1146 1146 1146 1146 1146\n",
            "(1146, 5)\n",
            "OCR --- 1.3729405403137207 seconds ---\n",
            "Dataframe Shape:   (1146, 5)\n",
            "Dataframe Shape After remove NA:   (1146, 5)\n",
            "Dataframe Shape After remove Negative:   (1135, 5)\n",
            "/content/g_output/w9_forms_261_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1135 1135\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6358938217163086 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_258.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.6616177558898926 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_258_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.9697644710540771 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_256.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1160 1160 1160 1160 1160\n",
            "(1160, 5)\n",
            "OCR --- 1.412870168685913 seconds ---\n",
            "Dataframe Shape:   (1160, 5)\n",
            "Dataframe Shape After remove NA:   (1160, 5)\n",
            "Dataframe Shape After remove Negative:   (1149, 5)\n",
            "/content/g_output/w9_forms_256_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1149 1149\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7103674411773682 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_253.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.327425479888916 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_253_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5891377925872803 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_244.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1159 1159 1159 1159 1159\n",
            "(1159, 5)\n",
            "OCR --- 1.3262741565704346 seconds ---\n",
            "Dataframe Shape:   (1159, 5)\n",
            "Dataframe Shape After remove NA:   (1159, 5)\n",
            "Dataframe Shape After remove Negative:   (1148, 5)\n",
            "/content/g_output/w9_forms_244_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1148 1148\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5875113010406494 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_269.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1161 1161 1161 1161 1161\n",
            "(1161, 5)\n",
            "OCR --- 1.4071979522705078 seconds ---\n",
            "Dataframe Shape:   (1161, 5)\n",
            "Dataframe Shape After remove NA:   (1161, 5)\n",
            "Dataframe Shape After remove Negative:   (1151, 5)\n",
            "/content/g_output/w9_forms_269_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1151 1151\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.8354747295379639 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_272.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.2991502285003662 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_272_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5902528762817383 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_277.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1164 1164 1164 1164 1164\n",
            "(1164, 5)\n",
            "OCR --- 1.2579116821289062 seconds ---\n",
            "Dataframe Shape:   (1164, 5)\n",
            "Dataframe Shape After remove NA:   (1164, 5)\n",
            "Dataframe Shape After remove Negative:   (1153, 5)\n",
            "/content/g_output/w9_forms_277_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1153 1153\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5537183284759521 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_273.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1159 1159 1159 1159 1159\n",
            "(1159, 5)\n",
            "OCR --- 1.3090379238128662 seconds ---\n",
            "Dataframe Shape:   (1159, 5)\n",
            "Dataframe Shape After remove NA:   (1159, 5)\n",
            "Dataframe Shape After remove Negative:   (1148, 5)\n",
            "/content/g_output/w9_forms_273_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1148 1148\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5813868045806885 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_271.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.3436529636383057 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_271_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6300666332244873 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_279.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1162 1162 1162 1162 1162\n",
            "(1162, 5)\n",
            "OCR --- 1.3467535972595215 seconds ---\n",
            "Dataframe Shape:   (1162, 5)\n",
            "Dataframe Shape After remove NA:   (1162, 5)\n",
            "Dataframe Shape After remove Negative:   (1153, 5)\n",
            "/content/g_output/w9_forms_279_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1153 1153\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.631669044494629 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_281.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.397803783416748 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1146, 5)\n",
            "/content/g_output/w9_forms_281_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1146 1146\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.67085599899292 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_275.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.533865213394165 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_275_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.9837384223937988 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_282.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1159 1159 1159 1159 1159\n",
            "(1159, 5)\n",
            "OCR --- 1.608417272567749 seconds ---\n",
            "Dataframe Shape:   (1159, 5)\n",
            "Dataframe Shape After remove NA:   (1159, 5)\n",
            "Dataframe Shape After remove Negative:   (1148, 5)\n",
            "/content/g_output/w9_forms_282_ocr.csv\n",
            "1738 2301\n",
            "Total words and bboxs:  1148 1148\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.902508020401001 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_284.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1145 1145 1145 1145 1145\n",
            "(1145, 5)\n",
            "OCR --- 1.2748215198516846 seconds ---\n",
            "Dataframe Shape:   (1145, 5)\n",
            "Dataframe Shape After remove NA:   (1145, 5)\n",
            "Dataframe Shape After remove Negative:   (1134, 5)\n",
            "/content/g_output/w9_forms_284_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1134 1134\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.637190341949463 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_270.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1149 1149 1149 1149 1149\n",
            "(1149, 5)\n",
            "OCR --- 1.2756505012512207 seconds ---\n",
            "Dataframe Shape:   (1149, 5)\n",
            "Dataframe Shape After remove NA:   (1149, 5)\n",
            "Dataframe Shape After remove Negative:   (1138, 5)\n",
            "/content/g_output/w9_forms_270_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1138 1138\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5246572494506836 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_297.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.2380139827728271 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_297_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5381622314453125 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_316.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1147 1147 1147 1147 1147\n",
            "(1147, 5)\n",
            "OCR --- 1.2137513160705566 seconds ---\n",
            "Dataframe Shape:   (1147, 5)\n",
            "Dataframe Shape After remove NA:   (1147, 5)\n",
            "Dataframe Shape After remove Negative:   (1136, 5)\n",
            "/content/g_output/w9_forms_316_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1136 1136\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5174024105072021 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_292.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1150 1150 1150 1150 1150\n",
            "(1150, 5)\n",
            "OCR --- 1.4015042781829834 seconds ---\n",
            "Dataframe Shape:   (1150, 5)\n",
            "Dataframe Shape After remove NA:   (1150, 5)\n",
            "Dataframe Shape After remove Negative:   (1139, 5)\n",
            "/content/g_output/w9_forms_292_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1139 1139\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6965739727020264 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_294.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1155 1155 1155 1155 1155\n",
            "(1155, 5)\n",
            "OCR --- 1.2678825855255127 seconds ---\n",
            "Dataframe Shape:   (1155, 5)\n",
            "Dataframe Shape After remove NA:   (1155, 5)\n",
            "Dataframe Shape After remove Negative:   (1144, 5)\n",
            "/content/g_output/w9_forms_294_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1144 1144\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5486445426940918 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_302.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1154 1154 1154 1154 1154\n",
            "(1154, 5)\n",
            "OCR --- 1.2762343883514404 seconds ---\n",
            "Dataframe Shape:   (1154, 5)\n",
            "Dataframe Shape After remove NA:   (1154, 5)\n",
            "Dataframe Shape After remove Negative:   (1143, 5)\n",
            "/content/g_output/w9_forms_302_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1143 1143\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7041935920715332 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_314.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.2102952003479004 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1141, 5)\n",
            "/content/g_output/w9_forms_314_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1141 1141\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5006663799285889 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_290.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1150 1150 1150 1150 1150\n",
            "(1150, 5)\n",
            "OCR --- 1.1434824466705322 seconds ---\n",
            "Dataframe Shape:   (1150, 5)\n",
            "Dataframe Shape After remove NA:   (1150, 5)\n",
            "Dataframe Shape After remove Negative:   (1139, 5)\n",
            "/content/g_output/w9_forms_290_ocr.csv\n",
            "1681 2379\n",
            "Total words and bboxs:  1139 1139\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.41660737991333 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_313.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1146 1146 1146 1146 1146\n",
            "(1146, 5)\n",
            "OCR --- 1.2562909126281738 seconds ---\n",
            "Dataframe Shape:   (1146, 5)\n",
            "Dataframe Shape After remove NA:   (1146, 5)\n",
            "Dataframe Shape After remove Negative:   (1135, 5)\n",
            "/content/g_output/w9_forms_313_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1135 1135\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5405569076538086 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_285.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1163 1163 1163 1163 1163\n",
            "(1163, 5)\n",
            "OCR --- 1.2491543292999268 seconds ---\n",
            "Dataframe Shape:   (1163, 5)\n",
            "Dataframe Shape After remove NA:   (1163, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_285_ocr.csv\n",
            "1681 2378\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5444350242614746 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_309.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1148 1148 1148 1148 1148\n",
            "(1148, 5)\n",
            "OCR --- 1.373004674911499 seconds ---\n",
            "Dataframe Shape:   (1148, 5)\n",
            "Dataframe Shape After remove NA:   (1148, 5)\n",
            "Dataframe Shape After remove Negative:   (1137, 5)\n",
            "/content/g_output/w9_forms_309_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1137 1137\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7781834602355957 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_299.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1153 1153 1153 1153 1153\n",
            "(1153, 5)\n",
            "OCR --- 1.314267635345459 seconds ---\n",
            "Dataframe Shape:   (1153, 5)\n",
            "Dataframe Shape After remove NA:   (1153, 5)\n",
            "Dataframe Shape After remove Negative:   (1142, 5)\n",
            "/content/g_output/w9_forms_299_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1142 1142\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6166059970855713 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_305.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1157 1157 1157 1157 1157\n",
            "(1157, 5)\n",
            "OCR --- 1.2460367679595947 seconds ---\n",
            "Dataframe Shape:   (1157, 5)\n",
            "Dataframe Shape After remove NA:   (1157, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_305_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6696865558624268 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_317.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.2946457862854004 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_317_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.7294178009033203 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_325.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1148 1148 1148 1148 1148\n",
            "(1148, 5)\n",
            "OCR --- 1.2643108367919922 seconds ---\n",
            "Dataframe Shape:   (1148, 5)\n",
            "Dataframe Shape After remove NA:   (1148, 5)\n",
            "Dataframe Shape After remove Negative:   (1137, 5)\n",
            "/content/g_output/w9_forms_325_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1137 1137\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.553734540939331 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_322.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1145 1145 1145 1145 1145\n",
            "(1145, 5)\n",
            "OCR --- 1.1333608627319336 seconds ---\n",
            "Dataframe Shape:   (1145, 5)\n",
            "Dataframe Shape After remove NA:   (1145, 5)\n",
            "Dataframe Shape After remove Negative:   (1134, 5)\n",
            "/content/g_output/w9_forms_322_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1134 1134\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.417489767074585 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_338.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1156 1156 1156 1156 1156\n",
            "(1156, 5)\n",
            "OCR --- 1.2224178314208984 seconds ---\n",
            "Dataframe Shape:   (1156, 5)\n",
            "Dataframe Shape After remove NA:   (1156, 5)\n",
            "Dataframe Shape After remove Negative:   (1145, 5)\n",
            "/content/g_output/w9_forms_338_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1145 1145\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.547240972518921 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_319.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1160 1160 1160 1160 1160\n",
            "(1160, 5)\n",
            "OCR --- 1.2384884357452393 seconds ---\n",
            "Dataframe Shape:   (1160, 5)\n",
            "Dataframe Shape After remove NA:   (1160, 5)\n",
            "Dataframe Shape After remove Negative:   (1149, 5)\n",
            "/content/g_output/w9_forms_319_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1149 1149\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5264830589294434 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_326.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1144 1144 1144 1144 1144\n",
            "(1144, 5)\n",
            "OCR --- 1.2136647701263428 seconds ---\n",
            "Dataframe Shape:   (1144, 5)\n",
            "Dataframe Shape After remove NA:   (1144, 5)\n",
            "Dataframe Shape After remove Negative:   (1133, 5)\n",
            "/content/g_output/w9_forms_326_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1133 1133\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.5134174823760986 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_330.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1153 1153 1153 1153 1153\n",
            "(1153, 5)\n",
            "OCR --- 1.1544935703277588 seconds ---\n",
            "Dataframe Shape:   (1153, 5)\n",
            "Dataframe Shape After remove NA:   (1153, 5)\n",
            "Dataframe Shape After remove Negative:   (1142, 5)\n",
            "/content/g_output/w9_forms_330_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1142 1142\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4682321548461914 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_334.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1146 1146 1146 1146 1146\n",
            "(1146, 5)\n",
            "OCR --- 1.391674280166626 seconds ---\n",
            "Dataframe Shape:   (1146, 5)\n",
            "Dataframe Shape After remove NA:   (1146, 5)\n",
            "Dataframe Shape After remove Negative:   (1135, 5)\n",
            "/content/g_output/w9_forms_334_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1135 1135\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.855219841003418 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_323.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1152 1152 1152 1152 1152\n",
            "(1152, 5)\n",
            "OCR --- 1.3217222690582275 seconds ---\n",
            "Dataframe Shape:   (1152, 5)\n",
            "Dataframe Shape After remove NA:   (1152, 5)\n",
            "Dataframe Shape After remove Negative:   (1140, 5)\n",
            "/content/g_output/w9_forms_323_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1140 1140\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.786916732788086 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_318.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1146 1146 1146 1146 1146\n",
            "(1146, 5)\n",
            "OCR --- 1.3286004066467285 seconds ---\n",
            "Dataframe Shape:   (1146, 5)\n",
            "Dataframe Shape After remove NA:   (1146, 5)\n",
            "Dataframe Shape After remove Negative:   (1135, 5)\n",
            "/content/g_output/w9_forms_318_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1135 1135\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.6912312507629395 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_332.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1148 1148 1148 1148 1148\n",
            "(1148, 5)\n",
            "OCR --- 1.1339881420135498 seconds ---\n",
            "Dataframe Shape:   (1148, 5)\n",
            "Dataframe Shape After remove NA:   (1148, 5)\n",
            "Dataframe Shape After remove Negative:   (1137, 5)\n",
            "/content/g_output/w9_forms_332_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1137 1137\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.4277076721191406 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "/content/drive/MyDrive/visual-doc-data/w9-ssn-fixed/dataset/test-data/w9_forms_327.jpg\n",
            "<class 'bytes'>\n",
            "Google OCR Used \n",
            "1158 1158 1158 1158 1158\n",
            "(1158, 5)\n",
            "OCR --- 1.3483471870422363 seconds ---\n",
            "Dataframe Shape:   (1158, 5)\n",
            "Dataframe Shape After remove NA:   (1158, 5)\n",
            "Dataframe Shape After remove Negative:   (1147, 5)\n",
            "/content/g_output/w9_forms_327_ocr.csv\n",
            "1758 2275\n",
            "Total words and bboxs:  1147 1147\n",
            "torch.Size([1, 512, 29])\n",
            "[]\n",
            "File processed --- 1.637803554534912 seconds ---\n",
            "-----------------------------------------------------------------------------------\n",
            "--- 258.3303337097168 seconds ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "from nltk import pos_tag\n",
        "from nltk.tree import Tree\n",
        "from nltk.chunk import conlltags2tree\n",
        "start_time = time.time()\n",
        "\n",
        "ocr_type='Model-GO'\n",
        "#ocr_type='Model-PTO'\n",
        "\n",
        "output_dir=\"/content/g_output/\"\n",
        "for i in range(len(file_list)):\n",
        "#for i in range(2,4):\n",
        "    filepath=input_dir_name+file_list[i]\n",
        "    filename, file_extension = os.path.splitext(file_list[i])\n",
        "    outpath=output_dir+filename+\".csv\"\n",
        "    print(filepath)\n",
        "    with open(filepath, \"rb\") as image:\n",
        "        image_content = image.read()\n",
        "    print(type(image_content))\n",
        "    result=get_pan_model_go(image_content,ocr_type,filename)\n",
        "    #result_dict={\"result\":result}\n",
        "    #with open(output_dir+filename+\".json\", 'w',encoding=\"utf-8\") as fp:\n",
        "      #json.dump(result_dict, fp)\n",
        "    #print(result)\n",
        "    result_list=[]\n",
        "    for j in range(len(result)):\n",
        "      #print(result[j]['label'].lower(),result[j]['text'],'NA')\n",
        "      result_list.append((str(result[j][1]).lower(),result[j][0],'NA'))\n",
        "\n",
        "    df = pd.DataFrame(result_list, columns=['Key','Value','confidence'])\n",
        "    df.to_csv(outpath,index=False)\n",
        "    print(\"-----------------------------------------------------------------------------------\")\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KGMqil6dhhLy",
        "outputId": "fc02e1e9-d03f-4c88-88b9-c4adf33f315f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/visual-doc-data/w9/lmv2-pred/50-ssn/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "src = \"/content/g_output/\"\n",
        "dst = \"/content/drive/MyDrive/visual-doc-data/w9/lmv2-pred/50-ssn/\"\n",
        "\n",
        "shutil.copytree(src, dst, dirs_exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dcsQkWKkXStM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4937db6fe1b043c887fa86ebb4d0fd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10ab33cf01b3486197f365cd54fe028b",
              "IPY_MODEL_1d8c54f468d24c3781700b9d04841ca6",
              "IPY_MODEL_9d84e835f7f342189282671bebecbc44"
            ],
            "layout": "IPY_MODEL_5a630ad62f4d48b3b5f4896d664772d8"
          }
        },
        "10ab33cf01b3486197f365cd54fe028b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8e13a3f63140cdad012b2b8ac0592a",
            "placeholder": "​",
            "style": "IPY_MODEL_75c30bcb71944c5a91dd5a43d8fd55b4",
            "value": "100%"
          }
        },
        "1d8c54f468d24c3781700b9d04841ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d49fea6bfde54637bd5b11b3544c836e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78a247e69d9247ceaabb7536d7f7262b",
            "value": 1
          }
        },
        "9d84e835f7f342189282671bebecbc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d84ba536f743678d7bbded215e6bc6",
            "placeholder": "​",
            "style": "IPY_MODEL_61bc57599bb54200aa0bc85c73f772b4",
            "value": " 1/1 [00:08&lt;00:00,  9.00s/ba]"
          }
        },
        "5a630ad62f4d48b3b5f4896d664772d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf8e13a3f63140cdad012b2b8ac0592a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c30bcb71944c5a91dd5a43d8fd55b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d49fea6bfde54637bd5b11b3544c836e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78a247e69d9247ceaabb7536d7f7262b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07d84ba536f743678d7bbded215e6bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61bc57599bb54200aa0bc85c73f772b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38e994a246e94330a802662929dd53df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55e15cfe9f734971982667b34ec61fa7",
              "IPY_MODEL_06361584c9284355b6b7f1be7e80f2e6",
              "IPY_MODEL_c8cda3f1020541bb8eef3428808244c9"
            ],
            "layout": "IPY_MODEL_b71113a1f96f48e39c3bf7ac70f81f2b"
          }
        },
        "55e15cfe9f734971982667b34ec61fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cdf5ff065df4190a0cd4da33ef5081a",
            "placeholder": "​",
            "style": "IPY_MODEL_8fc1f241043547ef99440b1c26b030d9",
            "value": "100%"
          }
        },
        "06361584c9284355b6b7f1be7e80f2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ab2a779e494b3485611c077b83755d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_094fdcb2e83744469b685ed4ad32842d",
            "value": 1
          }
        },
        "c8cda3f1020541bb8eef3428808244c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7cf18cd03cd4ae18bfd3f104862c957",
            "placeholder": "​",
            "style": "IPY_MODEL_2cef21bf03a84df3ade7ebfd51935e0b",
            "value": " 1/1 [00:02&lt;00:00,  2.98s/ba]"
          }
        },
        "b71113a1f96f48e39c3bf7ac70f81f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cdf5ff065df4190a0cd4da33ef5081a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc1f241043547ef99440b1c26b030d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16ab2a779e494b3485611c077b83755d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "094fdcb2e83744469b685ed4ad32842d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7cf18cd03cd4ae18bfd3f104862c957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cef21bf03a84df3ade7ebfd51935e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}